[
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "A spatial analysis of access to greenspace and deprivation in Bradford\nUsing a GWR model to analyze the relationship between nearest greenspace and dimensions of deprivation by Output Area within the Bradford local authority district."
  },
  {
    "objectID": "projects/index.html#access-to-greenspace",
    "href": "projects/index.html#access-to-greenspace",
    "title": "Projects",
    "section": "",
    "text": "A spatial analysis of access to greenspace and deprivation in Bradford\nUsing a GWR model to analyze the relationship between nearest greenspace and dimensions of deprivation by Output Area within the Bradford local authority district."
  },
  {
    "objectID": "projects/access-to-greenspace/access-to-greenspace-bradford.html",
    "href": "projects/access-to-greenspace/access-to-greenspace-bradford.html",
    "title": "A spatial analysis of access to greenspace and deprivation in Bradford",
    "section": "",
    "text": "Return to the summary page or go back to the projects page."
  },
  {
    "objectID": "projects/access-to-greenspace/access-to-greenspace-bradford.html#introduction",
    "href": "projects/access-to-greenspace/access-to-greenspace-bradford.html#introduction",
    "title": "A spatial analysis of access to greenspace and deprivation in Bradford",
    "section": "1. Introduction",
    "text": "1. Introduction\nGreenspace is an important part of urban life, with benefits for humans and the environment. Analysing Bradford local authority district (LAD), this study builds on the growing literature addressing the challenge of greenspace accessibility by focusing on each deprivation dimension. Results show that considering deprivation and the relationship with greenspace in this greater level of detail is important for future policy and development."
  },
  {
    "objectID": "projects/access-to-greenspace/access-to-greenspace-bradford.html#background",
    "href": "projects/access-to-greenspace/access-to-greenspace-bradford.html#background",
    "title": "A spatial analysis of access to greenspace and deprivation in Bradford",
    "section": "2. Background",
    "text": "2. Background\n\n2.1. Why is greenspace important?\nNatural England (2023) estimates benefits of £6.6 billion in health, climate, and environmental gains from greenspace. However, a third of people do not have access to quality greenspace within a 15-minute walk of their home (Natural England, 2023). Public policy highlights commitments to improve this, with the Green Infrastructure Framework seeking to determine where greenspace is needed (Natural England, 2023).\n\n\n2.2. Why Bradford?\nBradford is the fifth largest district in England (CBMDC, 2021) and has a young population, ranking 4th for children aged 14 or less (21.4%) (CBMDC, 2022). Bradford is diverse – a third of people identify as Muslim, nearly 20% were born outside the UK, and 39% are Black, Asian, Mixed, or “Other” non-White ethnicities (ONS, 2023h). Over a fifth of the population have poor health, and a fifth are disabled (ONS, 2023h).\nGreenspace assets include extensive moorland and woodland as well as 36 council recognised parks (CBMDC, 2019). There are sports grounds and facilities, but not all are freely accessible. Limited utilisation data exists, but estimates suggest it is below national and regional averages, with surveys finding those most likely to utilise urban greenspace were ethnic minorities, households without a car, and people with children (CBMDC, 2019).\nThe council recognise the need to embed greenspace within long-term strategies. Key ambitions include ensuring greenspaces are safe and inclusive, improving health outcomes by prioritising investment for those most in need (CBMDC, 2021).\n\n\n2.3. Review of current literature\nAn increasing body of literature acknowledges the connection between greenspace access and overall health (Jia et al, 2021; Lachowycz and Jones, 2011; McCormick, 2017) and social benefits, including community cohesion (Barbosa et al, 2007). Methodologies vary, but most find deprived communities have the best access whilst utilisation levels are unclear, but perception of quality can limit use (Barbosa et al, 2007; Jones et al, 2009; Kessel et al, 2009; Roe et al, 2016). This quality issue is worse in deprived areas (Gidlow and Ellis, 2011; Mears et al, 2019).\nSeveral Bradford-specific studies exist. Mueller et al (2018) analysed health impacts and determined greenspace promotes an active lifestyle, and helps mitigate pollution, noise, and heat effects. McEachan et al (2018) demonstrated the positive impact greenspace had on children, but this impact differed by ethnicity, and perceived quality of greenspace was more important than quantity. Perception has also been linked to biodiversity and facilities (Wood et al, 2018)."
  },
  {
    "objectID": "projects/access-to-greenspace/access-to-greenspace-bradford.html#research-question",
    "href": "projects/access-to-greenspace/access-to-greenspace-bradford.html#research-question",
    "title": "A spatial analysis of access to greenspace and deprivation in Bradford",
    "section": "3. Research question",
    "text": "3. Research question\nNo literature reviewed analyses the dimensions of deprivation. This study aims to investigate whether there is a statistically significant relationship between greenspace access and each dimension of the 2021 UK Census deprivation measure. The null hypothesis is that there is not a statistically significant relationship present.\nThe remainder of this notebook will be structured as follows: Section 4 explains the datasets used; Section 5 outlines data wrangling processes preparing for analysis; Section 6 presents visual analyses and statistical descriptors of the data; Section 7 includes analysis and results of the OLS regression, Moran’s I and LISA cluster evaluation, and subsequent GWR model; Section 8 discusses findings, how this could influence policy, and further opportunities to improve this study; Section 9 draws conclusions from the findings."
  },
  {
    "objectID": "projects/access-to-greenspace/access-to-greenspace-bradford.html#data",
    "href": "projects/access-to-greenspace/access-to-greenspace-bradford.html#data",
    "title": "A spatial analysis of access to greenspace and deprivation in Bradford",
    "section": "4. Data",
    "text": "4. Data\n\n4.1. Import libraries\n# Set number of threads to recommended 7 to avoid errors in code during visualisation phase\nimport os\nos.environ[\"OMP_NUM_THREADS\"] = '7'\n# Dataframe libraries\nimport pandas as pd\nimport geopandas as gpd\n\n# Visualisation libraries\nimport matplotlib.pyplot as plt\nimport folium\nimport contextily as ctx\nimport seaborn as sns\nimport matplotlib.patches as mpatches\nimport matplotlib.colors as mcolors\nfrom matplotlib.lines import Line2D\n\n# Regression libraries\nimport statsmodels.api as sm # add statsmodels\nfrom statsmodels.sandbox.regression.predstd import wls_prediction_std # for predictions\n\n# Spatial analysis libraries\nfrom pysal.lib import weights\nfrom pysal.lib import io\nfrom pysal.explore import esda\nfrom pysal.viz import splot\nfrom splot.esda import moran_scatterplot, lisa_cluster, plot_local_autocorrelation\nfrom mgwr.gwr import GWR, MGWR\nfrom mgwr.sel_bw import Sel_BW\n\n# Other required libraries\n%matplotlib inline\nimport numpy as np\nfrom scipy.stats import probplot\nimport scipy.stats as stats\n\n\n4.2. Import each datafile\nLinks to datafiles are located in the appendix to this notebook and can be downloaded and saved locally using the links provided.\n\n4.2.1. Output Areas (OAs)\nOAs are the lowest census geography level, containing 40 to 250 households (ONS, 2021), enabling more accurate nearest greenspace measurements, and capturing localised differences in deprivation. Polygons and population weighted centroids (PWCs) are available from the ONS (2023a, 2023b). PWCs are used to measure distance to greenspace as it captures the nearest greenspace for most households. Polygons are aggregated to Bradford LAD level using the ONS (2023c) lookup. This is necessary to reduce the OA PWCs and greenspace to those within Bradford LAD.\n# OA polygons (BFC: Full resolution - clipped to the coastline (Mean High Water mark)) (ONS, 2023a)\nOA_polygons = gpd.read_file('Data/Output_Areas_2021_EW_BFC_V8/OA_2021_EW_BFC_V8.shp')\n\n# OA Population-weighted centroids (ONS, 2023b)\nOA_PWC = gpd.read_file('Data/Output_Areas_2021_PWC_V3/PopCentroids_EW_2021_V3.shp')\n# OA to LSOA to MSOA to LAD lookup (ONS, 2023c)\nOA_lookup = pd.read_csv('Data/Output_Area_Lookup_in_England_and_Wales_v3.csv')\n\n### Error can be ignored - it is because of Welsh spellings in a certain column.\n### This is not relevant to, nor will it affect, this study as these columns/rows will not be used.\n\n\n4.2.2. Greenspace\nGreenspace data (OS, 2023) include site (polygon) and access (point) data. However, not all sites have access data, hence only sites are used to ensure all eligible greenspace is captured. Distance from the PWC to nearest greenspace will be calculated using these polygons. Data includes parks, gardens, sports facilities, and religious grounds, but does not include forests, woodland, moorland or canal and river paths (OS, 2023).\n# Greenspace site polygons (OS, 2023)\nGB_greenspace_site = gpd.read_file('Data/OS Open Greenspace (ESRI Shape File) GB/data/GB_GreenspaceSite.shp')\n\n\n4.2.3. Independent variables\nEach deprivation dimension (education, employment, health and disability, and housing) can be obtained via custom ONS queries (ONS, 2023d; ONS, 2023e; ONS, 2023f; ONS, 2023g). These queries include only Bradford LAD OAs. Each file contains the number of households that are deprived or not deprived, from which percentage of households deprived in each dimension is calculated (Section 5.4.) creating the independent variables for regression modelling.\n# Data for Bradford OAs only, from 2021 Census\n\n# Household deprivation in the education dimension (ONS, 2023d)\nHHD_dep_education_raw = pd.read_csv('Data/2021 Census Data/Household deprived in the education dimension.csv')\n\n# Household deprivation in the employment dimension (ONS, 2023e)\nHHD_dep_employment_raw = pd.read_csv('Data/2021 Census Data/Household deprived in the employment dimension.csv')\n\n# Household deprivation in the health and disability dimension (ONS, 2023f)\nHHD_dep_health_raw = pd.read_csv('Data/2021 Census Data/Household deprived in the health and disability dimension.csv')\n\n# Household deprivation in the housing dimension (ONS, 2023g)\nHHD_dep_housing_raw = pd.read_csv('Data/2021 Census Data/Household deprived in the housing dimension.csv')"
  },
  {
    "objectID": "projects/access-to-greenspace/access-to-greenspace-bradford.html#data-wrangling",
    "href": "projects/access-to-greenspace/access-to-greenspace-bradford.html#data-wrangling",
    "title": "A spatial analysis of access to greenspace and deprivation in Bradford",
    "section": "5. Data wrangling",
    "text": "5. Data wrangling\n\n5.1. OAs\nOnly Bradford LAD OAs are needed. The OA lookup and geometry dataframes can be merged, retaining only Bradford as identified by the LAD22NM column. There are 1,575 OAs within Bradford LAD.\n# Remove unnecessary columns from OA lookup, keeping only required columns in new dataframe\nOA_lookup_trim = OA_lookup[['OA21CD','LAD22CD','LAD22NM']]\n# Filter OA lookup to just Bradford\nBradford_OA_lookup = OA_lookup_trim[OA_lookup_trim['LAD22NM'] == 'Bradford']\n# Check how many OAs are left - this number is an important reference point for further data wrangling tasks\nlen(Bradford_OA_lookup)\n1575\n# Merge Bradford_OA_lookup with OA polygons to reduce the geodataframe containing the polygons to only Bradford OAs\nBradford_OA_polygons = OA_polygons.merge(Bradford_OA_lookup, how='right', on='OA21CD')\n# Check number of OAs is same as in the reduced Bradford OA lookup dataframe\nprint(len(Bradford_OA_polygons))\nprint(len(Bradford_OA_polygons) == len(Bradford_OA_lookup))\n1575\nTrue\n# Merge Bradford_OA_lookup with OA PWCs to reduce the geodataframe containing the PWCs to only Bradford OAs\nBradford_OA_PWC = OA_PWC.merge(Bradford_OA_lookup, how='right', on='OA21CD')\n# Check number of OAs is same as in the reduced Bradford OA lookup dataframe\nprint(len(Bradford_OA_PWC))\nprint(len(Bradford_OA_PWC) == len(Bradford_OA_lookup))\n1575\nTrue\n# Drop unrequired columns\nBradford_OA_polygons_tidy = Bradford_OA_polygons.drop([\n    'LSOA21CD','LSOA21NM','LSOA21NMW','BNG_E','BNG_N','LAT','LONG','GlobalID','LAD22CD','LAD22NM'], axis=1)\nBradford_OA_PWC_tidy = Bradford_OA_PWC.drop(['GlobalID','LAD22CD','LAD22NM'], axis=1)\n\n# Rename geometry columns and set geometry\nBradford_OA_polygons = Bradford_OA_polygons_tidy.set_geometry('geometry').rename_geometry('Polygon')\nBradford_OA_PWC = Bradford_OA_PWC_tidy.set_geometry('geometry').rename_geometry('PWC')\n\n\n5.2. Greenspace\nOnly greenspace within Bradford LAD is required. A Bradford LAD polygon is created to spatially match the greenspace, retaining only sites within Bradford LAD.\n\n5.2.1. Clean greenspace dataframe\nSome types of greenspaces are arguably not for recreation (e.g. cemetery) and some are not always free to the public (e.g. golf course). To ensure this analysis includes only freely accessible greenspace for recreational use, types are reduced to ‘play space’, ‘playing field’ and ‘public park or garden’.\n# Remove unnecessary columns, keeping only required columns in new dataframe\nGB_greenspace_site_trim = GB_greenspace_site[['id','function','geometry']]\n\n# Rename remaining columns for clarity\nGB_greenspace_site_trim = GB_greenspace_site_trim.rename(columns={\"id\": \"Greenspace_ID\", \"function\": \"Type\"})\nGB_greenspace_site_trim = GB_greenspace_site_trim.set_geometry('geometry').rename_geometry('Polygon')\n# Check what types are included in the data\nGB_greenspace_site_trim.Type.value_counts()\n\n\n\nType\n\n\n\n\n\nPlay Space\n42972\n\n\nReligious Grounds\n22229\n\n\nPlaying Field\n21377\n\n\nOther Sports Facility\n15073\n\n\nAllotments Or Community Growing Spaces\n13002\n\n\nPublic Park Or Garden\n11982\n\n\nCemetery\n7559\n\n\nTennis Court\n6632\n\n\nBowling Green\n6589\n\n\nGolf Course\n3000\n\n\n\nName: count, dtype: int64\n# Keep only 'Play Space', 'Playing Field', and 'Public Park Or Garden'\nGB_greenspace_site_filtered = GB_greenspace_site_trim.loc[GB_greenspace_site_trim['Type'].\n                                                          isin(['Play Space','Playing Field','Public Park Or Garden'])]\n\n\n5.2.2. Greenspace within Bradford LAD\nAggregating OA polygons to a single polygon and spatially matching to the greenspace dataframe isolates greenspace within Bradford LAD. This will be used to calculate the dependent variable for the regression analysis.\n# Create a copy of the Bradford_OA_polygons dataframe which will become the Bradford polygon dataframe\nBradford = Bradford_OA_polygons\n# Add a 'Bradford' dummy column to aggregate on\nBradford['City'] = 'Bradford'\n# Create a single polygon aggregated to the city level using 'dissolve'\nBradford_polygon = Bradford.dissolve(by='City')\n# Drop OA21CD column as this is no longer relevant\nBradford_polygon = Bradford_polygon.drop(['OA21CD'], axis=1)\n# Spatial join for any greenspace that intersects the Bradford polygon\nBradford_greenspace_site = gpd.sjoin(GB_greenspace_site_filtered, Bradford_polygon, how='inner', predicate='intersects')\n# Drop index_right column as this is no longer relevant\nBradford_greenspace_site = Bradford_greenspace_site.drop(['index_right'], axis=1)\n# Check length of dataframe to determine how many greenspaces are included\nlen(Bradford_greenspace_site)\n436\n# Check that the unique number of Greenspace_IDs is in fact the length of the dataframe\nprint(Bradford_greenspace_site['Greenspace_ID'].nunique())\nprint(len(Bradford_greenspace_site) == Bradford_greenspace_site['Greenspace_ID'].nunique())\n436\nTrue\n\n\n\n5.3. Dependent variable\nThe dependent variable is the distance between the OA PWC and nearest greenspace polygon calculated using the Euclidian distance and given in metres.\n# Find the nearest greenspace to each OA population-weighted centroid\nnearest_greenspace = gpd.sjoin_nearest(\n    Bradford_OA_PWC, Bradford_greenspace_site, how='left', distance_col='Distance')\n\n# Drop the unrequired columns\nnearest_greenspace = nearest_greenspace.drop(['PWC','index_right'], axis=1)\n# Check length of dataframe is equal to the length of the OA dataframe - i.e. one greenspace per OA has been identified\nprint(len(nearest_greenspace))\nprint(len(nearest_greenspace) == len(Bradford_OA_lookup))\n1599\nFalse\nThe information above shows there are some duplicated rows. This is confirmed by checking the number of unique OA21CDs which should be 1,575.\n# Check number of OA21CDs\nprint(nearest_greenspace['OA21CD'].nunique())\nprint(nearest_greenspace['OA21CD'].nunique() == len(Bradford_OA_lookup))\n1575\nTrue\nDuplicates are caused by the same greenspace being allocated different ‘Types’ with unique IDs. These duplicates are removed, keeping the first record irrespective of ‘Type’ as no analysis is to be conducted on this.\n# Isolate duplicated rows and check cause\n# Confirmed as duplicated sites with different Greenspace_IDs due to different greenspace Type being recorded\nduplicated_rows = nearest_greenspace[nearest_greenspace.duplicated(subset='OA21CD', keep=False)]\nduplicated_rows.head(6)\n\n\n\n\n\n\nOA21CD\n\n\nGreenspace_ID\n\n\nType\n\n\nDistance\n\n\n\n\n\n\n11\n\n\nE00053364\n\n\n0295ED18-F337-5C37-E063-AAEFA00A445E\n\n\nPlay Space\n\n\n514.057891\n\n\n\n\n11\n\n\nE00053364\n\n\n0295ED18-F2F3-5C37-E063-AAEFA00A445E\n\n\nPlaying Field\n\n\n514.057891\n\n\n\n\n42\n\n\nE00053392\n\n\n0295ED18-F337-5C37-E063-AAEFA00A445E\n\n\nPlay Space\n\n\n364.166159\n\n\n\n\n42\n\n\nE00053392\n\n\n0295ED18-F2F3-5C37-E063-AAEFA00A445E\n\n\nPlaying Field\n\n\n364.166159\n\n\n\n\n43\n\n\nE00053393\n\n\n0295ED18-F337-5C37-E063-AAEFA00A445E\n\n\nPlay Space\n\n\n571.723915\n\n\n\n\n43\n\n\nE00053393\n\n\n0295ED18-F2F3-5C37-E063-AAEFA00A445E\n\n\nPlaying Field\n\n\n571.723915\n\n\n\n\n# Drop duplicated rows and keep first row for duplicated instances\nunique_nearest_greenspace = nearest_greenspace.drop_duplicates(subset='OA21CD', keep='first')\n# Check length of dataframe is now as expected\nprint(len(unique_nearest_greenspace))\nprint(len(unique_nearest_greenspace) == len(Bradford_OA_lookup))\n1575\nTrue\nThe ‘Bradford_greenspace_site’ dataframe created in 5.2. must also be updated to ensure a consistent view of greenspace.\n# Get unique list of Greenspace_IDs\nunique_Greenspace_IDs = unique_nearest_greenspace[['Greenspace_ID']].drop_duplicates()\n# Join onto Bradford_greenspace_site to reduce this dataframe to just those kept in the unique_nearest_greenspace dataframe\nBradford_greenspace_site_unique = Bradford_greenspace_site.merge(unique_Greenspace_IDs, how='right', on='Greenspace_ID')\n\n\n5.4. Independent variables\nDeprivation data needs to be pivoted to create columns of the datapoints by OA and converting these into percentages. This is achieved using a function to repeat the process for each dimension. Resulting dataframes are merged into a final dataframe containing all four independent variables.\ndef Independent_Variables_Setup(dataframe, dataframe_name):     # dataframe as object, dataframe_name as string\n    \n    # Create all required strings for naming dataframes throughout wrangling process\n    core_name = dataframe_name.rstrip('_raw') # Remove \"_raw\" from end of dataframe to get core name\n    dropped = core_name + '_dropped'          # Add \"_dropped\" to end of core name\n    pivot = core_name + '_pivot'              # Add \"_pivot\" to end of core name\n    percentage = core_name + '_PC'            # Add \"_PC\" to end of core name\n    \n    # Drop columns that are not required\n    cols = [1,3]     # List of column indexes of the columns to drop\n    dropped = dataframe.drop(dataframe.columns[cols], axis=1)     # Create new dataframe with columns dropped\n    \n    # Pivot the table on column[0], making the options from column[1] the new column headers and the data that from column[2]\n    pivot = dropped.pivot_table(index=dropped.columns[0],\n                                  columns=dropped.columns[1],\n                                  values=dropped.columns[2]).reset_index()\n    pivot.columns.name = None\n    \n    # Create a Total column from 3 new data columns[1,2,3]\n    pivot['Total'] = pivot.iloc[:, 1:4].sum(axis=1)\n    \n    # Calculate % HHDs Deprived by dividing column[3] \"Deprived\" by the Total calculated above\n    pivot[percentage] = (pivot.iloc[:,3]/pivot['Total'])\n    \n    # Create final dataframe keeping only the OA21CD and % HHDs deprived in the given dimension\n    final_cols = [0,5]\n    core_name = pivot.iloc[:, final_cols]\n    \n    return core_name\n# Household deprivation in the education dimension\nHHD_dep_education = Independent_Variables_Setup(HHD_dep_education_raw, 'HHD_dep_education_raw')\n# Household deprivation in the employment dimension\nHHD_dep_employment = Independent_Variables_Setup(HHD_dep_employment_raw, 'HHD_dep_employment_raw')\n# Household deprivation in the health and disability dimension\nHHD_dep_health = Independent_Variables_Setup(HHD_dep_health_raw, 'HHD_dep_health_raw')\n# Household deprivation in the housing dimension\nHHD_dep_housing = Independent_Variables_Setup(HHD_dep_housing_raw, 'HHD_dep_housing_raw')\n# Check all 4 dataframes are the same length and that length is as expected\nlen(HHD_dep_education) == len(HHD_dep_employment) == len(HHD_dep_health) == len(HHD_dep_housing) == len(Bradford_OA_lookup)\nTrue\n# Merge education and employment\nInd_vars = HHD_dep_education.merge(HHD_dep_employment, how='inner', on='Output Areas Code')\n# Add health\nInd_vars = Ind_vars.merge(HHD_dep_health, how='inner', on='Output Areas Code')\n# Add housing\nInd_vars = Ind_vars.merge(HHD_dep_housing, how='inner', on='Output Areas Code')\n# Final length check\nprint(len(Ind_vars))\nprint(len(Ind_vars) == len(Bradford_OA_lookup))\n1575\nTrue\n\n\n5.5. Final dataframe for regression analysis\nA dataframe containing the dependent and independent variables, OA code and polygons is required for the regression models and spatial analysis.\n# Merge the unique_nearest_greenspace and Ind_vars dataframes to get a final dataframe for subsequent analysis\nfinal_df = unique_nearest_greenspace.merge(Ind_vars, how='inner', left_on='OA21CD', right_on='Output Areas Code')\nfinal_df = final_df.merge(Bradford_OA_polygons, how='inner', on='OA21CD')\n\n# Drop unrequired columns\nfinal_df = final_df.drop(['Output Areas Code', 'Greenspace_ID', 'Type', 'City'], axis=1)\n\n# Set geometry\nfinal_df = final_df.set_geometry('Polygon')\nVisual checks of each dataframe can be found in Appendix 1."
  },
  {
    "objectID": "projects/access-to-greenspace/access-to-greenspace-bradford.html#visualisation-and-statistics",
    "href": "projects/access-to-greenspace/access-to-greenspace-bradford.html#visualisation-and-statistics",
    "title": "A spatial analysis of access to greenspace and deprivation in Bradford",
    "section": "6. Visualisation and Statistics",
    "text": "6. Visualisation and Statistics\n\n6.1. OAs\nFigure 6.1.1. shows OA boundaries and PWCs within Bradford LAD. PWCs locations can vary from near the edge to the centre of OAs.\n\nFigure 6.1.1. Map of OA polygons and population-weighted centroids within the Bradford LAD\n\nData Source: ONS, 2023a; ONS, 2023b\n\n# Plot polygons\nfig, ax = plt.subplots(figsize=(10, 10))\nBradford_OA_polygons.plot(ax=ax, color='Grey', edgecolor='black', linewidth=0.25, alpha=0.1)\n\n# Plot points\nBradford_OA_PWC.plot(ax=ax, markersize=1, color='#134f5c')\n\n# Customize plot\nax.set_axis_off()\n\n# Add basemap\nctx.add_basemap(ax, crs=Bradford_OA_polygons.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n\n# Show plot\nplt.show()\n\n\n\npng\n\n\n\n\n\n6.2. Greenspace\nFigure 6.2.1. shows greenspace by type. However, as detailed in Section 5.3., duplicates were removed by keeping first instances of duplicated cases hence counts in figure 6.2.2. are skewed. In most instances, ‘playing field’ was retained, and so counts are higher for this type. This does not impact subsequent analysis as type does not feature in the regression modelling.\n\nFigure 6.2.1. Map of greenspace within the Bradford LAD\n\nData Source: OS, 2023\n\n# Plot polygons\nfig, ax = plt.subplots(figsize=(15, 15))\n\n# Plot Bradford_polygon\nBradford_polygon.plot(ax=ax, color='Grey', edgecolor='black', linewidth=0.25, alpha=0.1)\n\n# Plot Bradford_greenspace_site_unique\nBradford_greenspace_site_unique.plot(ax=ax, column='Type', cmap='viridis',\n                                     legend=True, markersize=50, alpha=0.75, edgecolor='black', linewidth=0.25)\n\n# Add basemap\nctx.add_basemap(ax, crs=Bradford_polygon.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n\n# Customize plot\nax.set_axis_off()\n\n# Show plot\nplt.show()\n\n\n\npng\n\n\n\n\nFigure 6.2.2. Count of greenspace by type within the Bradford LAD\n\nData Source: OS, 2023; Author's calculations\n\ngreenspace_types = Bradford_greenspace_site_unique['Type'].unique().tolist()     # Get list of greenspace types\ngreenspace_counts = list(Bradford_greenspace_site_unique['Type'].value_counts()) # Get list of greenspace type counts\n\ncolours = ['#21918c', '#440154', '#fde725']     # Set colours from the map for visual consistency\n\n# Create a pie chart\nfig, ax = plt.subplots()\nwedges, labels = ax.pie(greenspace_counts, labels=greenspace_types,     # counts as data, types as labels\n                        autopct=None, startangle=90,                    # turn off data labels, set start angle to 90degrees\n                        wedgeprops=dict(width=0.5), colors=colours)     # set size of donut hole, set colour scheme\n\n# Add labels within each pie piece\nfor label, value in zip(labels, greenspace_counts):\n    label.set(size=10, text=f'{label.get_text()}: {value}')     # Set the labels to be \"Type: Count\"\n\n\n# Equal aspect ratio to make sure the chart is drawn as a circle\nax.axis('equal')  \n\n# Add a title\nplt.title('Count of greenspace by type within the Bradford LAD',\n          fontweight='bold', fontsize=12, fontfamily='sans-serif') # Change title to specified font settings\n\n# Add a footnote with the data source and specify location on visual\nplt.text(0.5, -0.15, \"Data Source: OS, 2023; Author's calculations\",\n         ha=\"center\", va=\"center\", transform=plt.gca().transAxes,\n         fontsize=8, color=\"gray\")\n\n# Display the pie chart\nplt.show()\n\n\n\npng\n\n\n\n\n\n6.3. Deprivation\ndef create_deprivation_choropleth(variable, final_df):\n    # Create a copy of final_df so data and column names can be made visual-appropriate\n    OA_choropleth = final_df.copy()\n    \n    # Multiply data by 100 to create percentage in readable format for the choropleth\n    OA_choropleth[['HHD_dep_education_PC', 'HHD_dep_employment_PC', \n                   'HHD_dep_health_PC', 'HHD_dep_housing_PC']] = (\n        OA_choropleth[['HHD_dep_education_PC', 'HHD_dep_employment_PC', \n                       'HHD_dep_health_PC', 'HHD_dep_housing_PC']] * 100).round(1)\n    \n    # Create a dictionary of current independent variable column names with long-form for use on map\n    columns_dict = {\"HHD_dep_education_PC\": \"Households deprived in the education dimension (%)\",\n                    \"HHD_dep_employment_PC\": \"Households deprived in the employment dimension (%)\",\n                    \"HHD_dep_health_PC\": \"Households deprived in the health dimension (%)\",\n                    \"HHD_dep_housing_PC\": \"Households deprived in the housing dimension (%)\"}\n    \n    # Rename the columns to the long-form version\n    OA_choropleth.rename(columns=columns_dict, inplace=True)\n    \n    # Write long-form column name to a new variable to use in the choropleth code\n    variable_longform = columns_dict[variable]\n\n    # Plot choropleth\n    fig, ax = plt.subplots(figsize=(15, 15))\n    OA_choropleth.plot(column=variable_longform, \n                       ax=ax, \n                       scheme='EqualInterval', \n                       k=5, \n                       cmap='YlGnBu', \n                       legend=True)\n    \n    # Add basemap\n    ctx.add_basemap(ax, crs=OA_choropleth.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n\n    # Customize plot\n    ax.set_axis_off()\n    \n    # Add title to legend\n    legend_title = variable_longform\n    ax.get_legend().set_title(legend_title)\n\n    # Show plot\n    plt.show()\nFigure 6.3.1. shows areas of high education deprivation in the southeast and west. Lowest levels are in rural, affluent areas in the southwest and north.\n\nFigure 6.3.1. Percentage of households deprived in the education dimension by OA in Bradford LAD\n\nData Source: ONS, 2023d; Author's calculations\n\n# Call the function with the desired variable and the dataframe\ncreate_deprivation_choropleth('HHD_dep_education_PC', final_df)\n\n\n\npng\n\n\nFigure 6.3.2. shows similar spatial employment deprivation patterns to education. The range of employment deprivation is smaller though, from 0% to 54.7%.\n\n\nFigure 6.3.2. Percentage of households deprived in the employment dimension by OA in Bradford LAD\n\nData Source: ONS, 2023e; Author's calculations\n\n# Call the function with the desired variable and the dataframe\ncreate_deprivation_choropleth('HHD_dep_employment_PC', final_df)\n\n\n\npng\n\n\nFigure 6.3.3. shows health deprivation levels are higher and widely spread. As health deprivation includes poor health and disability, levels may be higher due to factors including elderly populations, as well as affluence-associated poor health.\n\n\nFigure 6.3.3. Percentage of households deprived in the health dimension by OA in Bradford LAD\n\nData Source: ONS, 2023f; Author's calculations\n\n# Call the function with the desired variable and the dataframe\ncreate_deprivation_choropleth('HHD_dep_health_PC', final_df)\n\n\n\npng\n\n\nContrastingly, figure 6.3.4. shows housing deprivation is largely isolated to Bradford city and around Keighley. Most OAs have less than 10% housing deprivation.\n\n\nFigure 6.3.4. Percentage of households deprived in the housing dimension by OA in Bradford LAD\n\nData Source: ONS, 2023g; Author's calculations\n\n# Call the function with the desired variable and the dataframe\ncreate_deprivation_choropleth('HHD_dep_housing_PC', final_df)\n\n\n\npng\n\n\nFigure 6.3.5. and 6.3.6. provide key summary statistics. Education deprivation has the largest range, from 2.2% in the least deprived OA to 67.8% in the most deprived. Only education and health dimensions exceed 0% in all OAs. For health, the lowest level of deprivation is 8.8% highlighting how even the most affluent areas are impacted by this.\nEducation, health, and housing have outliers at the higher end, recording maximum values around 65-68%. However, average deprivation levels vary across each dimension, with housing having the lowest average (11.0%) and health the highest (35.4%). There is no consistent distribution or spatial pattern to deprivation across all four dimensions.\n\n\nFigure 6.3.5. Boxplots of the percentage of households deprived in the given dimension by OA in Bradford LAD\n\nData Source: ONS, 2023d; ONS, 2023e; ONS, 2023f; ONS, 2023g; Author's calculations\n\n# Create a copy of the Ind_vars dataframe for the purposes of this boxplot\nInd_vars_boxplot = Ind_vars\n\n# Multiply data by 100 to create percentage in readable format\nInd_vars_boxplot[['HHD_dep_education_PC', 'HHD_dep_employment_PC', \n                  'HHD_dep_health_PC', 'HHD_dep_housing_PC']] = (\n    Ind_vars_boxplot[['HHD_dep_education_PC', 'HHD_dep_employment_PC', \n                      'HHD_dep_health_PC', 'HHD_dep_housing_PC']] * 100).round(1)\n\n# Rename the columns for the chart to be clearer\nInd_vars_boxplot = Ind_vars_boxplot.rename(columns={\n    \"HHD_dep_education_PC\": \"Education\",\n    \"HHD_dep_employment_PC\": \"Employment\",\n    \"HHD_dep_health_PC\": \"Health\",\n    \"HHD_dep_housing_PC\": \"Housing\"})\n\n# Setup figure and boxplot\nfig, ax = plt.subplots(figsize=(10, 6))\nwandering_forest_palette = ['#09435a', '#4e7d8e', '#9cc2b8', '#90958f']   # Create colour palette\nsns.set_palette(wandering_forest_palette)     # Set colour palette\nsns.boxplot(data=Ind_vars_boxplot)     # Add data\n\n# Add title and amend axes\nplt.title('Percentage of households deprived in the given dimension',\n          fontweight='bold', fontsize=12) # Change title to specified font settings\nplt.xlabel(\"Household deprivation dimension\", fontweight='bold') # set x-axis label and font\nplt.ylabel(\"Percentage of households deprived (%)\", fontweight='bold') # set y-axis label and font\n\n# Add a footnote with the data source and specify location on visual\nplt.text(0.5, -0.15, \"Data Source: ONS, 2023d; ONS, 2023e; ONS, 2023f; ONS, 2023g\",\n         ha=\"center\", va=\"center\", transform=plt.gca().transAxes,\n         fontsize=8, color=\"gray\")\n\nplt.show()\n\n\n\npng\n\n\n\n\nFigure 6.3.6. Deprivation statistics in the given dimension by OA in Bradford LAD\n\nData Source: ONS, 2023d; ONS, 2023e; ONS, 2023f; ONS, 2023g; Author's calculations\n\n# Get precise figures as shown in the boxplot\nInd_vars_boxplot.describe()\n\n\n\n\n\n\nEducation\n\n\nEmployment\n\n\nHealth\n\n\nHousing\n\n\n\n\n\n\ncount\n\n\n1575.000000\n\n\n1575.000000\n\n\n1575.000000\n\n\n1575.000000\n\n\n\n\nmean\n\n\n24.954095\n\n\n15.573143\n\n\n35.444508\n\n\n10.959619\n\n\n\n\nstd\n\n\n10.980256\n\n\n9.313979\n\n\n8.980795\n\n\n9.729166\n\n\n\n\nmin\n\n\n2.200000\n\n\n0.000000\n\n\n8.800000\n\n\n0.000000\n\n\n\n\n25%\n\n\n16.900000\n\n\n8.000000\n\n\n29.100000\n\n\n3.900000\n\n\n\n\n50%\n\n\n23.900000\n\n\n13.800000\n\n\n34.800000\n\n\n7.600000\n\n\n\n\n75%\n\n\n31.600000\n\n\n22.000000\n\n\n41.000000\n\n\n15.150000\n\n\n\n\nmax\n\n\n67.800000\n\n\n54.700000\n\n\n66.100000\n\n\n64.800000\n\n\n\n\n\n\n\n6.4. Distance to nearest greenspace\nFigure 6.4.1. shows distances to greenspace are greater in rural areas to the north and west. These areas are more affluent, with lower levels of deprivation (figures 6.3.1.-6.3.4). More deprived OAs have lower distances.\n\nFigure 6.4.1. Distance to nearest greenspace (metres) by OA in Bradford LAD\n\nData Source: ONS, 2023b; OS, 2023; Author's calculations\n\ndef create_distance_choropleth(final_df):\n    # Create a copy of final_df so data and column names can be made visual-appropriate\n    OA_dist_choropleth = final_df.copy()\n    \n    # Round distance to the nearest metre\n    OA_dist_choropleth['Distance'] = OA_dist_choropleth['Distance'].round().astype(int)\n    \n    # Create a dictionary of current distance column name with long-form for use on map\n    distance_dict = {\"Distance\": \"Distance to nearest greenspace (metres)\"}\n    \n    # Rename the column to the long-form version\n    rename_column = OA_dist_choropleth.rename(columns=distance_dict, inplace=True)\n    \n    # Write long-form column name to a new variable to use in the choropleth code\n    distance_longform = 'Distance to nearest greenspace (metres)'\n\n    # Plot choropleth\n    fig, ax = plt.subplots(figsize=(15, 15))\n    OA_dist_choropleth.plot(column=distance_longform, \n                            ax=ax, \n                            scheme='NaturalBreaks', \n                            cmap='YlGnBu', \n                            legend=True)\n    \n    # Add basemap\n    ctx.add_basemap(ax, crs=OA_dist_choropleth.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n\n    # Customize plot\n    ax.set_axis_off()\n    \n    # Add title to legend\n    ax.get_legend().set_title(distance_longform)\n\n    # Show plot\n    plt.show()\n# Call the function with the DataFrame final_df\ncreate_distance_choropleth(final_df)\n\n\n\npng\n\n\nFigure 6.4.2. shows outliers at larger distances, confirming the distance variable is right skewed. Meanwhile, figure 6.4.3. shows the range, from 0m to over 2,000m. OAs with 0m distance are a result of PWCs falling within greenspace boundaries. On average, greenspace is around 275m from PWCs, which is below the previous UK government target of 300m (Houlden et al, 2019).\n\n\nFigure 6.4.2. Boxplot of distance to nearest greenspace (metres) by OA in Bradford LAD\n\nData Source: ONS, 2023b; OS, 2023; Author's calculations\n\n# Setup figure and boxplot\nfig, ax = plt.subplots(figsize=(10, 6))\nsns.boxplot(unique_nearest_greenspace, x='Distance', color='#e1fdd5')     # Add data and change colour\n\n# Add title and amend axes\nplt.title('Distance to nearest greenspace by OA in Bradford',\n          fontweight='bold', fontsize=12) # Change title to specified font settings\nax.set(xlabel=\"\") # Set ax xlabel to nothing so the variable name does not appear\nplt.xlabel(\"Distance to nearest greenspace (metres)\", fontweight='bold') # set x-axis label and font\nplt.ylabel(\"OAs\", fontweight='bold') # set y-axis label and font\n\n# Set the x-axis ticks at 250 increments\ntick_locations = np.arange(0, 2251, 250)\nax.set_xticks(tick_locations)\n\n# Add a footnote with the data source and specify location on visual\nplt.text(0.5, -0.15, \"Data Source: ONS, 2023b; OS, 2023; Author's calculations\",\n         ha=\"center\", va=\"center\", transform=plt.gca().transAxes,\n         fontsize=8, color=\"gray\")\n\nplt.show()\n\n\n\npng\n\n\n\n\nFigure 6.4.3. Distance to nearest greenspace (metres) statistics by OA in Bradford LAD\n\nData Source: ONS, 2023b; OS, 2023; Author's calculations\n\n# Get precise figures as shown in the boxplot\nunique_nearest_greenspace.describe()\n\n\n\n\n\n\nDistance\n\n\n\n\n\n\ncount\n\n\n1575.000000\n\n\n\n\nmean\n\n\n247.661399\n\n\n\n\nstd\n\n\n183.485184\n\n\n\n\nmin\n\n\n0.000000\n\n\n\n\n25%\n\n\n119.213902\n\n\n\n\n50%\n\n\n201.468622\n\n\n\n\n75%\n\n\n332.656088\n\n\n\n\nmax\n\n\n2090.986345\n\n\n\n\n\n\n\n6.5. Dependent and independent variables\nFigure 6.5.1. shows scatter plots and regression lines between the dependent and independent variables. There is one high distance outlier visible across all four dimensions, and all present a negative correlation with distance to nearest greenspace.\n\nFigure 6.5.1. Scatterplots of distance to nearest greenspace (metres) and household deprivation dimensions, by OA in Bradford LAD\n\nData Source: ONS, 2023b; ONS, 2023d; ONS, 2023e; ONS, 2023f; ONS, 2023g; OS, 2023; Author's calculations\n\n# Set up a figure with 2 rows and 2 columns for subplots\nfig, axs = plt.subplots(2, 2, figsize=(15, 10), sharey=True, sharex=True) # Share axes across 4 plots for visual consistency\n\n# Add title, x-axis subtitle, and y-axis labels\nplt.title('Distance to nearest greenspace compared to Household Deprivation Dimensions', \n          x=-0.15, y=2.25, fontweight='bold', fontsize=12)\nfig.suptitle('Household Deprivation Dimension', y=0.05, fontweight='bold', fontsize=12)\naxs[0,0].set_ylabel('Distance to nearest greenspace (metres)', fontweight='bold', fontsize=12)\naxs[1,0].set_ylabel('Distance to nearest greenspace (metres)', fontweight='bold', fontsize=12)\n\n\n### Education scatter\naxs[0,0].scatter(x=final_df['HHD_dep_education_PC'], y=final_df['Distance'], s=3, c='#09435a') # add data and set colour\naxs[0,0].set_xlabel('Education (%)', fontsize=12) # add axis label and set font\n\n# Calculate the regression line\nslope0, intercept0 = np.polyfit(final_df['HHD_dep_education_PC'], final_df['Distance'], 1)\nregression_line0 = np.polyval([slope0, intercept0], final_df['HHD_dep_education_PC'])\n\n# Add this to the chart\naxs[0,0].plot(final_df['HHD_dep_education_PC'], regression_line0, color='red')\n\n\n### Employment scatter\naxs[0,1].scatter(x=final_df['HHD_dep_employment_PC'], y=final_df['Distance'], s=3, c='#4e7d8e') # add data and set colour\naxs[0,1].set_xlabel('Employment (%)', fontsize=12) # add axis label and set font\n\n# Calculate the regression line\nslope1, intercept1 = np.polyfit(final_df['HHD_dep_employment_PC'], final_df['Distance'], 1)\nregression_line1 = np.polyval([slope1, intercept1], final_df['HHD_dep_employment_PC'])\n\n# Add this to the chart\naxs[0,1].plot(final_df['HHD_dep_employment_PC'], regression_line1, color='red')\n\n\n### Health scatter\naxs[1,0].scatter(x=final_df['HHD_dep_health_PC'], y=final_df['Distance'], s=3, c='#9cc2b8') # add data and set colour\naxs[1,0].set_xlabel('Health (%)', fontsize=12) # add axis label and set font\n\n# Calculate the regression line\nslope2, intercept2 = np.polyfit(final_df['HHD_dep_health_PC'], final_df['Distance'], 1)\nregression_line2 = np.polyval([slope2, intercept2], final_df['HHD_dep_health_PC'])\n\n# Add this to the chart\naxs[1,0].plot(final_df['HHD_dep_health_PC'], regression_line2, color='red')\n\n\n### Housing scatter\naxs[1,1].scatter(x=final_df['HHD_dep_housing_PC'], y=final_df['Distance'], s=3, c='#90958f') # add data and set colour\naxs[1,1].set_xlabel('Housing (%)', fontsize=12) # add axis label and set font\n\n# Calculate the regression line\nslope3, intercept3 = np.polyfit(final_df['HHD_dep_housing_PC'], final_df['Distance'], 1)\nregression_line3 = np.polyval([slope3, intercept3], final_df['HHD_dep_housing_PC'])\n\n# Add this to the chart\naxs[1,1].plot(final_df['HHD_dep_housing_PC'], regression_line3, color='red')\n\n\n# Add a footnote with the data source and specify location on visual\nplt.text(-0.15, -0.3,\n         \"Data Source: ONS, 2023b; ONS, 2023d; ONS, 2023e; ONS, 2023f; ONS, 2023g; OS, 2023; Author's calculations\",\n         ha=\"center\", va=\"center\", transform=plt.gca().transAxes,\n         fontsize=10, color=\"gray\")\n\n\nplt.show()\n\n\n\npng"
  },
  {
    "objectID": "projects/access-to-greenspace/access-to-greenspace-bradford.html#analysis-and-results",
    "href": "projects/access-to-greenspace/access-to-greenspace-bradford.html#analysis-and-results",
    "title": "A spatial analysis of access to greenspace and deprivation in Bradford",
    "section": "7. Analysis and results",
    "text": "7. Analysis and results\n\n7.1. OLS Regression\nChecks for collinearity are conducted using a correlation matrix (figure 7.1.1.). Deprivation variables have a positive correlation with one another, particularly employment and health. Figure 7.1.2. is a coefficient matrix which confirms that the employment and health dimensions have a coefficient of 0.68 which is high and could indicate collinearity. People with poorer health or disabilities are more likely to be out of work (ONS, 2023i) and so, coupled with the high coefficient, it has been determined that collinearity is present between these variables.\n\nFigure 7.1.1. Correlation matrix of independent and dependent variables by OA in Bradford LAD\n\nData Source: ONS, 2023b; ONS, 2023d; ONS, 2023e; ONS, 2023f; ONS, 2023g; OS, 2023; Author's calculations\n\n# Initial correlations to check for collinearity\noutput = pd.plotting.scatter_matrix(final_df, alpha=0.2, figsize=(12, 12), diagonal='kde')\n\n\n\npng\n\n\n\n\nFigure 7.1.2. Coefficient matrix of independent and dependent variables by OA in Bradford LAD\n\nData Source: ONS, 2023b; ONS, 2023d; ONS, 2023e; ONS, 2023f; ONS, 2023g; OS, 2023; Author's calculations\n\n# Correlation coefficient matrix\nfinal_df.corr(numeric_only=True)\n\n\n\n\n\n\nDistance\n\n\nHHD_dep_education_PC\n\n\nHHD_dep_employment_PC\n\n\nHHD_dep_health_PC\n\n\nHHD_dep_housing_PC\n\n\n\n\n\n\nDistance\n\n\n1.000000\n\n\n-0.182102\n\n\n-0.181204\n\n\n-0.160042\n\n\n-0.148355\n\n\n\n\nHHD_dep_education_PC\n\n\n-0.182102\n\n\n1.000000\n\n\n0.620664\n\n\n0.643816\n\n\n0.358545\n\n\n\n\nHHD_dep_employment_PC\n\n\n-0.181204\n\n\n0.620664\n\n\n1.000000\n\n\n0.680197\n\n\n0.624160\n\n\n\n\nHHD_dep_health_PC\n\n\n-0.160042\n\n\n0.643816\n\n\n0.680197\n\n\n1.000000\n\n\n0.272581\n\n\n\n\nHHD_dep_housing_PC\n\n\n-0.148355\n\n\n0.358545\n\n\n0.624160\n\n\n0.272581\n\n\n1.000000\n\n\n\n\n\n\nAddressing collinearity\nFigure 7.1.3. shows the p-value for employment is highest, meaning it is the least statistically significant variable, so employment is removed to eliminate the identified collinearity.\n# Create the independent Y variable\ny = final_df['Distance']\n\n# Create the dependent X variables\nX = final_df[['HHD_dep_education_PC','HHD_dep_employment_PC','HHD_dep_health_PC','HHD_dep_housing_PC']]\n\n# Add the constant\nx1 = sm.add_constant(X)\n# Create OLS regression model\nmod = sm.OLS(y, x1)\n# Fit the model and save results\nresults = mod.fit()\n\n\nFigure 7.1.3. Results of OLS model including all four deprivation dimensions\n\nData Source: ONS, 2023b; ONS, 2023d; ONS, 2023e; ONS, 2023f; ONS, 2023g; OS, 2023; Author's calculations\n\n# Print results summary\nprint(results.summary())\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:               Distance   R-squared:                       0.044\nModel:                            OLS   Adj. R-squared:                  0.042\nMethod:                 Least Squares   F-statistic:                     18.13\nDate:                Mon, 13 May 2024   Prob (F-statistic):           1.43e-14\nTime:                        19:16:44   Log-Likelihood:                -10408.\nNo. Observations:                1575   AIC:                         2.083e+04\nDf Residuals:                    1570   BIC:                         2.085e+04\nDf Model:                           4                                         \nCovariance Type:            nonrobust                                         \n=========================================================================================\n                            coef    std err          t      P&gt;|t|      [0.025      0.975]\n-----------------------------------------------------------------------------------------\nconst                   351.9268     20.166     17.452      0.000     312.373     391.481\nHHD_dep_education_PC   -165.8278     57.102     -2.904      0.004    -277.831     -53.824\nHHD_dep_employment_PC   -78.8281     86.937     -0.907      0.365    -249.352      91.696\nHHD_dep_health_PC       -99.3122     77.368     -1.284      0.199    -251.068      52.443\nHHD_dep_housing_PC     -140.5889     61.893     -2.271      0.023    -261.991     -19.187\n==============================================================================\nOmnibus:                      685.269   Durbin-Watson:                   1.660\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5645.947\nSkew:                           1.830   Prob(JB):                         0.00\nKurtosis:                      11.523   Cond. No.                         26.7\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nOLS regression model\nThe model includes education, health, and housing deprivation dimensions. Figure 7.1.4. shows that all three are statistically significant at the 95% confidence level. The model has an R-squared value of 0.044, meaning only 4.4% of variance is accounted for. Further analysis of the residuals is warranted.\n# Create the independent Y variable\ny = final_df['Distance']\n\n# Create the dependent X variables\nX = final_df[['HHD_dep_education_PC','HHD_dep_health_PC','HHD_dep_housing_PC']]\n\n# Add the constant\nx1 = sm.add_constant(X)\n# Create OLS regression model\nmod = sm.OLS(y, x1)\n# Fit the model and save results\nresults = mod.fit()\n\nFigure 7.1.4. Results of OLS model including education, health, and housing deprivation dimensions\n\n\nData Source: ONS, 2023b; ONS, 2023d; ONS, 2023f; ONS, 2023g; OS, 2023; Author's calculations\n\n# Print results summary\nprint(results.summary())\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:               Distance   R-squared:                       0.044\nModel:                            OLS   Adj. R-squared:                  0.042\nMethod:                 Least Squares   F-statistic:                     23.91\nDate:                Mon, 13 May 2024   Prob (F-statistic):           3.95e-15\nTime:                        19:16:44   Log-Likelihood:                -10408.\nNo. Observations:                1575   AIC:                         2.082e+04\nDf Residuals:                    1571   BIC:                         2.085e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n========================================================================================\n                           coef    std err          t      P&gt;|t|      [0.025      0.975]\n----------------------------------------------------------------------------------------\nconst                  359.1799     18.510     19.405      0.000     322.873     395.487\nHHD_dep_education_PC  -177.5110     55.626     -3.191      0.001    -286.620     -68.402\nHHD_dep_health_PC     -135.9300     65.988     -2.060      0.040    -265.364      -6.496\nHHD_dep_housing_PC    -173.7491     49.930     -3.480      0.001    -271.686     -75.812\n==============================================================================\nOmnibus:                      689.258   Durbin-Watson:                   1.658\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5763.638\nSkew:                           1.837   Prob(JB):                         0.00\nKurtosis:                      11.621   Cond. No.                         19.1\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nAnalysis of observed versus fitted values and residuals\n\n# Obtain residuals from results\nresiduals = results.resid\n# Creating a DataFrame with 'OA21CD' and residuals\nresiduals_data = pd.DataFrame({\n    'OA21CD': final_df['OA21CD'],\n    'Residuals': residuals\n})\n\n# Add Residuals to final_df\nfinal_df = pd.merge(final_df, residuals_data, on='OA21CD')\nFigure 7.1.5. illustrates the relationship between the observed distances and fitted values from the model. There is an outlier – the largest distance in the observed values is no longer the largest in the fitted values – and fitted values have a much smaller range with the largest distance being closer to 325m.\n\n\nFigure 7.1.5. Observed vs Fitted Values for the OLS regression model\n\nData Source: Author's calculations\n\n# Set up a figure\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Set axis labels and title\nplt.xlabel('Fitted values - Distance (metres)', fontweight='bold', fontsize=12)\nplt.ylabel('Observed values - Distance (metres)', fontweight='bold', fontsize=12)\nplt.title('Observed vs Fitted Values for the OLS regression model', fontweight='bold')\n\n# Scatter plot showing Fitted against Observed values\nplt.scatter(x=results.fittedvalues, y=y, label='Data', s=3, c='#09435a') # add data and set colour and size of circles\n\n# Plot the line y=x\nplt.plot([min(results.fittedvalues), max(results.fittedvalues)],\n         [min(results.fittedvalues), max(results.fittedvalues)], linestyle='--', color='red', label='y=x')\n\n\n# Set the y-axis ticks at 250 increments\ntick_locations = np.arange(0, 2251, 250)\nax.set_yticks(tick_locations)\n\n# Add legend\nplt.legend()\n\nplt.show()\n\n\n\npng\n\n\nFigure 7.1.6. shows the variance in the residuals. No distinct relationship is visible with positive and negative residuals ranging from around -250 to +250, across all fitted distance values. This suggests the assumption that the relationship is linear is reasonable, and the variance of the error terms are equal. However, only larger positive residuals exist, meaning the model is not working as well for largest distances in the observed values.\n\n\nFigure 7.1.6. Residuals vs Fitted Values for the OLS regression model\n\nData Source: Author's calculations\n\n# Set up a figure\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Set axis labels and title\nplt.xlabel('Fitted values - Distance (metres)', fontweight='bold', fontsize=12)\nplt.ylabel('Residuals', fontweight='bold', fontsize=12)\nplt.title('Residuals vs Fitted Values for the OLS regression model', fontweight='bold')\n\n# Scatter plot showing Fitted values against Residuals\nplt.scatter(x=results.fittedvalues, y=final_df['Residuals'], label='Data', s=3, c='#09435a') # add data and set colour/size\n\n# Add dashed horizontal line at y=0\nplt.axhline(0, linestyle='--', color='black', linewidth=0.8)\n\n# Set the x-axis ticks at 250 increments\ntick_locations = np.arange(-250, 2001, 250)\nax.set_yticks(tick_locations)\n\nplt.show()\n\n\n\npng\n\n\nTo confirm this, figure 7.1.6. shows a histogram of the residuals, highlighting a normal distribution centred around 0, with a slight right skew.\n\n\nFigure 7.1.7. Histogram of residuals for the OLS regression model\n\nData Source: Author's calculations\n\n# Set up a figure\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Plot histogram of residuals\nsns.histplot(x=residuals, bins=50, ax=ax)\n\n# Set the x-axis ticks at 250 increments\ntick_locations = np.arange(-250, 2001, 250)\nax.set_xticks(tick_locations)\n\n# Label axes\nax.set_xlabel('Residuals', fontweight='bold')\nax.set_ylabel('Count', fontweight='bold')\n\n# Title and show the plot\nplt.title('Histogram of Residuals from OLS model', fontweight='bold', fontsize=12)\nplt.show()\n\n\n\npng\n\n\nLastly, a Q-Q plot is used to confirm the presence of outliers. One extreme outlier was visible in the previous charts, but a Q-Q plot allows for confirmation of other outliers closer to the rest of the data points. Figure 7.1.8. confirms that there are outliers in the residuals at both the top and bottom end.\n\n\nFigure 7.1.8. Q-Q Plot\n\nData Source: Author's calculations\n\n# Create a figure and axis\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Create a Q-Q plot\nprobplot(residuals, dist=\"norm\", plot=plt)\n\n# Add title and label axes\nplt.title(\"Q-Q Plot\", fontweight='bold')\nplt.xlabel(\"Theoretical Quantiles\", fontweight='bold')\nplt.ylabel(\"Ordered Values\", fontweight='bold')\n\n# Change colour of circles\nax.lines[0].set_markerfacecolor('#4e7d8e')\nax.lines[0].set_markeredgecolor('#4e7d8e')\n\nplt.show()\n\n\n\npng\n\n\n\n\n\n7.2. Moran’s I\nMoran’s I is used to detect high and low values concentrated spatially, and the spatial relationship between neighbours is random if zero association is found (Paez and Scott, 2004). Queens weights are used, meaning any OA bordering the given OA is included.\nThe I value is 0.46 and the p-value is 0.001. These are positive and significant respectively, implying distance to nearest greenspace is spatially correlated - higher values and lower values cluster spatially. Figure 7.2.1. shows this on a scatterplot.\n# Calculate the queen weights based on the OA\nw_queen = weights.Queen.from_dataframe(final_df, ids = 'OA21CD')\n# Calculate Moran's I using queen weights\nmi = esda.Moran(final_df['Distance'], w_queen)\n# I value\nprint(f'I value: {mi.I}')\n\n# Significance (p value)\nprint(f'P value: {mi.p_sim}')\n\n\n\nI value\n0.45882055605281585\n\n\n\n\nP value\n0.001\n\n\n\n\nFigure 7.2.1. Moran Scatterplot\n\nData Source: Author's calculations\n\nfig, ax = plt.subplots(figsize=(9, 9))  # Set figure size\nmoran_scatterplot(mi, ax=ax)  # Create Moran's I scatterplot\n\n# Change the color and size of points\nscatter_plot = ax.get_children()[0]\nscatter_plot.set_facecolor('#09435a')\nscatter_plot.set_edgecolor('#09435a')\nscatter_plot.set_sizes([10])\n\n# Show the plot\nplt.show()\n\n\n\npng\n\n\nTo minimise outlier impact, the distance value for this OA will be reduced to the second highest value.\n# Find maximum distance\nfinal_df['Distance'].max()\n2090.9863451326555\n# Find the second highest distance\nfinal_df[final_df['Distance'] &lt; final_df['Distance'].max()]['Distance'].max()\n1268.1070267044204\ndistance_sort = final_df.Distance.tolist() # Create a list of distances\ndistance_sort.remove(max(distance_sort)) # Remove maximum value\n# Set the new max (second highest)\nfinal_df['Distance_Clean'] = final_df.Distance #create a new column\nfinal_df.loc[final_df['Distance']&gt;1500, 'Distance_Clean'] = max(distance_sort) \n# If the distance is greater than 1500 in the original variable, set it equal to the maximum value of our cleaned variable\n# Use 1500 as a buffer to the actual 2nd highest distance shown in the previous cell\n# Check new max is expected value\nprint(final_df['Distance_Clean'].max())\nprint(final_df['Distance_Clean'].max() == final_df[final_df['Distance'] &lt; final_df['Distance'].max()]['Distance'].max())\n1268.1070267044204\nTrue\nMoran’s I is re-calculated and the I value is now 0.47, and the p-value remains 0.001. These results are still positive and significant respectively, so distance to nearest greenspace remains spatially correlated. Figure 7.2.2. shows the outlier is removed.\n# Calculate new Moran's I using queen weights and cleaned Distance variable\nmi_adj = esda.Moran(final_df['Distance_Clean'], w_queen)\n# I value\nprint(f'I value: {mi_adj.I}')\n\n# Significance (p value)\nprint(f'P value: {mi_adj.p_sim}')\n\n\n\nI value\n0.47144858850487537\n\n\n\n\nP value\n0.001\n\n\n\n\n\nFigure 7.2.2. Moran Scatterplot (Adjusted)\n\nData Source: Author's calculations\n\nfig, ax = plt.subplots(figsize=(9, 9))  # Set figure size\nmoran_scatterplot(mi_adj, ax=ax)  # Create Moran's I scatterplot\n\n# Change the color and size of points\nscatter_plot = ax.get_children()[0]\nscatter_plot.set_facecolor('#09435a')\nscatter_plot.set_edgecolor('#09435a')\nscatter_plot.set_sizes([10])\n\n# Show the plot\nplt.show()\n\n\n\npng\n\n\n\n\n\n7.3. LISA Clusters\nSpatial association will be tested and visualised using Local Indicators of Spatial Association (LISA) clusters. This will be conducted on the dependent variable and residuals from Section 7.1.\n\nDistance\nSignificance is calculated to the 95% level and a LISA cluster assigned. Figure 7.3.1. shows each LISA cluster, with clear spatial patterns emerging. To the north and south, and north of Bradford city centre, there are High-High clusters, meaning these OAs have high distances to the nearest greenspace as do their neighbouring OAs. Meanwhile, Low-Low clusters can be observed around the city of Bradford suburbs and Keighley town centre.\n# Calculate LISA clusters\nlisa_Distance = esda.Moran_Local(final_df['Distance_Clean'], w_queen)\nfinal_df['Sig_Distance'] = lisa_Distance.p_sim &lt; 0.05 # Calculate a variable to show which are significant at the 95% level\nfinal_df['Quad_Distance'] = lisa_Distance.q # Calculate a variable indicating the respective quadrant\n# Create categorical column for the map visual\nfinal_df['LISA_Distance'] = np.select(\n    [\n        (final_df['Sig_Distance'] == False),\n        (final_df['Sig_Distance'] == True) & (final_df['Quad_Distance'] == 1),\n        (final_df['Sig_Distance'] == True) & (final_df['Quad_Distance'] == 2),\n        (final_df['Sig_Distance'] == True) & (final_df['Quad_Distance'] == 3),\n        (final_df['Sig_Distance'] == True) & (final_df['Quad_Distance'] == 4)\n    ],\n    [\n        'Not Significant',\n        'High-High',\n        'Low-High',\n        'Low-Low',\n        'High-Low'\n    ],\n    default='ERROR'  # Return \"ERROR\" string if conditions above are not met\n)\n\n\nFigure 7.3.1. Map of distance LISA Clusters by OA in Bradford LAD\n\nData Source: Author's calculations\n\ncustom_cmap = mcolors.ListedColormap(['#E14D2A','#FACF5A','#4F9DA6','#233142','lightGrey'])\n\nfig, ax = plt.subplots(figsize=(15, 15))\nfinal_df.plot(column='LISA_Distance', \n              ax=ax, \n              categorical=True,\n              legend=True, \n              cmap=custom_cmap)\n\n# Add basemap\nctx.add_basemap(ax, crs=final_df.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n\n# Customize plot\nax.set_axis_off()\n\n# Show plot\nplt.show()\n\n\n\npng\n\n\n\n\nResiduals\nFigure 7.3.2. shows similar spatial patterns for the residual LISA clusters. There is one noticeable OA to the north that is Low-High - this OA has a small residual error compared to neighbouring OAs – and fewer Low-High clusters in central areas. Despite these differences, spatial association is still present across much of the district.\n# Calculate LISA clusters\nlisa_Residuals = esda.Moran_Local(final_df['Residuals'], w_queen)\nfinal_df['Sig_Residuals'] = lisa_Residuals.p_sim &lt; 0.05 # Calculate a variable to show which are significant at the 95% level\nfinal_df['Quad_Residuals'] = lisa_Residuals.q # Calculate a variable indicating the respective quadrant\n# Create categorical column for the map visual\nfinal_df['LISA_Residuals'] = np.select(                                           # Select rows meeting following rules\n    [\n        (final_df['Sig_Residuals'] == False),                                     # Not significant\n        (final_df['Sig_Residuals'] == True) & (final_df['Quad_Residuals'] == 1),  # Significant and Quadrant 1\n        (final_df['Sig_Residuals'] == True) & (final_df['Quad_Residuals'] == 2),  # Significant and Quadrant 2\n        (final_df['Sig_Residuals'] == True) & (final_df['Quad_Residuals'] == 3),  # Significant and Quadrant 3\n        (final_df['Sig_Residuals'] == True) & (final_df['Quad_Residuals'] == 4)   # Significant and Quadrant 4\n    ],\n    [\n        'Not Significant',                                                        # Assign string based on above rules\n        'High-High',\n        'Low-High',\n        'Low-Low',\n        'High-Low'\n    ],\n    default='ERROR'  # Return \"ERROR\" string if conditions above are not met\n)\n\n\nFigure 7.3.2. Map of residual LISA Clusters by OA in Bradford LAD\n\nData Source: Author's calculations\n\nfig, ax = plt.subplots(figsize=(15, 15))\n\ncustom_cmap = mcolors.ListedColormap(['#E14D2A','#FACF5A','#4F9DA6','#233142','lightGrey'])\n\n# Plot choropleth map\nfinal_df.plot(column='LISA_Residuals', \n              ax=ax, \n              categorical=True,\n              legend=True, \n              cmap=custom_cmap)\n\n# Add basemap\nctx.add_basemap(ax, crs=final_df.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n\n# Customize plot\nax.set_axis_off()\n\n# Add title to legend\nax.get_legend().set_title('LISA Clusters for Residuals')\n\n# Show plot\nplt.show()\n\n\n\npng\n\n\nResults from the Moran’s I and LISA cluster analysis confirms a Geographically Weighted Regression (GWR) model is required to ensure spatial association is considered.\n\n\n\n7.4. GWR model\nBandwidth is the optimal number of datapoints that will be included in each local regression model. The bandwidth calculated is 54.0 – the 54 nearest datapoints of the 1,575 OAs in the dataset will be included, hence each local model will be using roughly 3% of the available data.\n# Split the geometry into X and Y columns\nBradford_OA_PWC_tidy['X'] = Bradford_OA_PWC_tidy['geometry'].x\nBradford_OA_PWC_tidy['Y'] = Bradford_OA_PWC_tidy['geometry'].y\n# Add this to the final_df\nfinal_df = final_df.merge(Bradford_OA_PWC_tidy, how='inner', on='OA21CD').drop(['geometry'], axis=1)\ng_coords = list(zip(final_df.X, final_df.Y)) # Create a list of x and y coordinates\n\n# Create y variable\ng_y = np.asarray(final_df.Distance_Clean).reshape((-1,1))\n\n# Create x variables\ng_X = final_df[['HHD_dep_education_PC', 'HHD_dep_health_PC', 'HHD_dep_housing_PC']]\ng_X = np.asarray(g_X)\n\ngwr_selector = Sel_BW(g_coords, g_y, g_X) #set parameters for calculating the bandwidth\n# Calculate optimised bandwidth\nbw = gwr_selector.search()\nprint(bw)\n54.0\nThe GWR model (figure 7.4.1) includes global regression results reflecting the OLS model (section 7.1), whilst GWR results give details of the local models. The R-squared value is 0.458 (45.8% of variance is accounted for) which is higher than the global regression model.\n# Create GWR model\ngwr = GWR(g_coords, g_y, g_X, bw)\n\n# Fit the model\ngwr_results = gwr.fit()\n\nFigure 7.4.1. Results of GWR model\n\nData Source: Author's calculations\n\n# View results summary\nprint(gwr_results.summary())\n===========================================================================\nModel type                                                         Gaussian\nNumber of observations:                                                1575\nNumber of covariates:                                                     4\n\nGlobal Regression Results\n---------------------------------------------------------------------------\nResidual sum of squares:                                       48341131.294\nLog-likelihood:                                                  -10371.107\nAIC:                                                              20750.214\nAICc:                                                             20752.253\nBIC:                                                           48329565.576\nR2:                                                                   0.045\nAdj. R2:                                                              0.043\n\nVariable                              Est.         SE  t(Est/SE)    p-value\n------------------------------- ---------- ---------- ---------- ----------\nX0                                 356.449     18.078     19.717      0.000\nX1                                -188.300     54.328     -3.466      0.001\nX2                                -123.805     64.449     -1.921      0.055\nX3                                -168.246     48.766     -3.450      0.001\n\nGeographically Weighted Regression (GWR) Results\n---------------------------------------------------------------------------\nSpatial kernel:                                           Adaptive bisquare\nBandwidth used:                                                      54.000\n\nDiagnostic information\n---------------------------------------------------------------------------\nResidual sum of squares:                                       27460005.829\nEffective number of parameters (trace(S)):                          269.555\nDegree of freedom (n - trace(S)):                                  1305.445\nSigma estimate:                                                     145.034\nLog-likelihood:                                                   -9925.735\nAIC:                                                              20392.580\nAICc:                                                             20505.314\nBIC:                                                              21843.301\nR2:                                                                   0.458\nAdjusted R2:                                                          0.346\nAdj. alpha (95%):                                                     0.001\nAdj. critical t value (95%):                                          3.380\n\nSummary Statistics For GWR Parameter Estimates\n---------------------------------------------------------------------------\nVariable                   Mean        STD        Min     Median        Max\n-------------------- ---------- ---------- ---------- ---------- ----------\nX0                      292.885    208.447   -231.865    259.474   1217.183\nX1                     -165.196    519.824  -1890.328   -113.466   1930.027\nX2                        6.041    578.986  -2557.624    -23.072   2446.111\nX3                     -291.652    856.329  -4271.564   -262.118   5015.975\n===========================================================================\n\nNone\nVisualising results requires defining the t-value significance. Figure 7.4.1. shows there are 1,305 degrees of freedom which, using a standard t-table, gives a significance value of -/+1.96 at the 0.05 level. This is the parameter used to assign significance.\nOn each choropleth, only OAs with a thick outline are significant in the t-value results. This highlights where there are, or are not, significant results in the local models. The colour shows whether these relationships (coefficients) are positive or negative.\n# Add GWR coeffients to final_df for each predictor variable\nfinal_df['GWR_Education_Coefficient'] = gwr_results.params[:,1]\nfinal_df['GWR_Health_Coefficient'] = gwr_results.params[:,2]\nfinal_df['GWR_Housing_Coefficient'] = gwr_results.params[:,3]\n# Add GWR t-values to final_df for each predictor variable\nfinal_df['GWR_Education_tvalue'] = gwr_results.tvalues[:,1]\nfinal_df['GWR_Health_tvalue'] = gwr_results.tvalues[:,2]\nfinal_df['GWR_Housing_tvalue'] = gwr_results.tvalues[:,3]\n# Function to create categorical column for the map visual based on t-value significance\ndef create_categorical(Variable):      # takes variable as string\n    new_col = Variable + '_significance'   # create new column name\n    final_df[new_col] = np.select(                                          # Select rows meeting following rules\n        [\n            (final_df[Variable] &lt; -1.96),                                   # t-value significance less than -1.96\n            (final_df[Variable] &gt; 1.96),                                    # t-value significance greater than 1.96\n            (final_df[Variable] &gt;= -1.96) & (final_df[Variable] &lt;= 1.96)    # t-value not significant\n        ],\n        [\n            'Significant (negative t-value)',                               # Assign string based on above rules\n            'Significant (positive t-value)',\n            'Not significant'\n        ],\n        default='ERROR'  # Return \"ERROR\" string if conditions above are not met\n    )\n# Add columns to dataframe using the function above\ncreate_categorical('GWR_Education_tvalue')\ncreate_categorical('GWR_Health_tvalue')\ncreate_categorical('GWR_Housing_tvalue')\n# Create subsets of the data for the purposes of the map visual\n# Only rows where the t-value is significant are needed to highlight the outline of the OAs on the map\nGWR_Emp_sig = final_df[(final_df['GWR_Education_tvalue_significance'] == 'Significant (negative t-value)') |\n                      (final_df['GWR_Education_tvalue_significance'] == 'Significant (positive t-value)')]\n\nGWR_Health_sig = final_df[(final_df['GWR_Health_tvalue_significance'] == 'Significant (negative t-value)') |\n                      (final_df['GWR_Health_tvalue_significance'] == 'Significant (positive t-value)')]\n\nGWR_Housing_sig = final_df[(final_df['GWR_Housing_tvalue_significance'] == 'Significant (negative t-value)') |\n                      (final_df['GWR_Housing_tvalue_significance'] == 'Significant (positive t-value)')]\ndef viz_coefficients_t_value(final_df, Coeff_variable, Sig_df, Sig_variable):\n    # Visualise the coefficients\n    fig, ax = plt.subplots(figsize=(15, 15))\n    \n    # Plot coefficients choropleth\n    coef_plot = final_df.plot(column=Coeff_variable, \n                              ax=ax, \n                              cmap='RdYlBu', \n                              scheme='userdefined', \n                              classification_kwds=dict(bins=[-1000, -500, 0, 500, 1000]), \n                              legend=True,\n                              legend_kwds={'title': 'Coefficients'},\n                              alpha=0.75)\n    \n    # Plot significance information\n    for index, row in Sig_df.iterrows():\n        if \"Significant\" in row[Sig_variable]:\n            if \"positive\" in row[Sig_variable]:\n                final_df[final_df['OA21CD'] == row['OA21CD']].plot(ax=ax, \n                                                                    color='none', \n                                                                    edgecolor='#000026', \n                                                                    linewidth=2)\n            elif \"negative\" in row[Sig_variable]:\n                final_df[final_df['OA21CD'] == row['OA21CD']].plot(ax=ax, \n                                                                    color='none', \n                                                                    edgecolor='#800020',  # Burgundy color\n                                                                    linewidth=2)\n        else:\n            final_df[final_df['OA21CD'] == row['OA21CD']].plot(ax=ax, \n                                                                color='none', \n                                                                edgecolor='none')\n\n    # Customize plot\n    ax.set_axis_off()\n    \n    # Add basemap\n    ctx.add_basemap(ax, crs=final_df.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n    \n    # Extract legend labels and handles\n    try:\n        coef_legend_elements = coef_plot.get_legend().legendHandles\n        coef_legend_labels = [text.get_text() for text in coef_plot.get_legend().get_texts()]\n    except AttributeError:\n        coef_legend_elements, coef_legend_labels = coef_plot.get_legend_handles_labels()\n    \n    # Create legend for both coefficient values and significance\n    sig_legend_elements = [Line2D([0], [0], color='#000026', lw=2, label='Positive Significant'),\n                           Line2D([0], [0], color='#800020', lw=2, label='Negative Significant')]\n    legend_handles = coef_legend_elements + sig_legend_elements\n    legend_labels = coef_legend_labels + ['Significant - positive t-value', 'Significant - negative t-value']\n    ax.legend(handles=legend_handles, labels=legend_labels, loc='upper right', title=\"Coefficients\")\n    \n    # Show plot\n    plt.show()\nFigure 7.4.2. shows statistically significant spatial patterns for education deprivation, with clusters of negative relationships in the north, west and central areas. This means that in these areas, as education deprivation increases, the distance to the nearest greenspace decreases. By contrast, clusters of positive relationships can be seen in the northwest and southeast.\n\n\nFigure 7.4.2. Map of GWR model results and significance for education deprivation, by OA in the Bradford LAD\n\nData Source: Author's calculations\n\n# Call the function with the required parameters\nviz_coefficients_t_value(final_df, 'GWR_Education_Coefficient', GWR_Emp_sig, 'GWR_Education_tvalue_significance')\n\n\n\npng\n\n\nHealth deprivation (figure 7.4.3.) displays clusters of negative relationships in the north and Bradford city centre. Positive relationships exist in the northwest, south and suburbs north of Bradford city centre. This contrasts education deprivation but is not unexpected given higher levels of health deprivation shown in figure 6.3.3. across the district and that the spatial pattern of this varied compared to other deprivation dimensions.\n\n\nFigure 7.4.3. Map of GWR model results and significance for health deprivation, by OA in the Bradford LAD\n\nData Source: Author's calculations\n\n# Call the function with the required parameters\nviz_coefficients_t_value(final_df, 'GWR_Health_Coefficient', GWR_Emp_sig, 'GWR_Health_tvalue_significance')\n\n\n\npng\n\n\nFigure 7.4.4. shows housing deprivation has large negative clusters in the north and south, and Bradford city centre. There are fewer statistically significant positive relationships across the district, with a small number in the north and east.\n\n\nFigure 7.4.4. Map of GWR model results and significance for housing deprivation, by OA in the Bradford LAD\n\nData Source: Author's calculations\n\n# Call the function with the required parameters\nviz_coefficients_t_value(final_df, 'GWR_Housing_Coefficient', GWR_Emp_sig, 'GWR_Housing_tvalue_significance')\n\n\n\npng\n\n\nLastly, mapping residuals of the GWR model demonstrate the change from the OLS regression model (figure 7.3.2.). Figure 7.4.5. shows the GWR model removed some residual autocorrelation but not all of it. This means some spatial variation has still not been captured. This is confirmed by recalculating the Moran’s I value and significance. The I value has decreased to 0.23 showing clustering has been reduced but is still present. The p-value of 0.001 shows this is statistically significant.\n# Add GWR residuals to the final_df\nfinal_df['GWR_residuals'] = gwr_results.resid_response\n# Calculate LISA clusters as before but with GWR_residuals\nlisa_GWR_Residuals = esda.Moran_Local(final_df['GWR_residuals'], w_queen)\n# Calculate the 95% significance and quadrants as before but for the GWR_Residuals\nfinal_df['Sig_GWR_Residuals'] = lisa_GWR_Residuals.p_sim &lt; 0.05\nfinal_df['Quad_GWR_Residuals'] = lisa_GWR_Residuals.q\n# Create categorical column for the map visual using if/and rules as before\nfinal_df['LISA_GWR_Residuals'] = np.select(\n    [\n        (final_df['Sig_GWR_Residuals'] == False),\n        (final_df['Sig_GWR_Residuals'] == True) & (final_df['Quad_GWR_Residuals'] == 1),\n        (final_df['Sig_GWR_Residuals'] == True) & (final_df['Quad_GWR_Residuals'] == 2),\n        (final_df['Sig_GWR_Residuals'] == True) & (final_df['Quad_GWR_Residuals'] == 3),\n        (final_df['Sig_GWR_Residuals'] == True) & (final_df['Quad_GWR_Residuals'] == 4)\n    ],\n    [\n        'Not Significant',\n        'High-High',\n        'Low-High',\n        'Low-Low',\n        'High-Low'\n    ],\n    default='ERROR'  # Return \"ERROR\" string if conditions above are not met\n)\n\n\nFigure 7.4.5. Map of GWR residual LISA Clusters by OA in Bradford LAD\n\nData Source: Author's calculations\n\n# Define custom colormap\ncustom_cmap = mcolors.ListedColormap(['#E14D2A','#FACF5A','#4F9DA6','#233142','lightGrey'])\n\n# Plot choropleth\nfig, ax = plt.subplots(figsize=(15, 15))\nfinal_df.plot(column='LISA_GWR_Residuals', \n              ax=ax, \n              categorical=True,\n              legend=True,\n              cmap=custom_cmap,  \n              edgecolor='black',\n              linewidth=0.25,\n              legend_kwds={'loc': 'upper right', 'title': 'LISA GWR Residuals'})\n\n# Add basemap\nctx.add_basemap(ax, crs=final_df.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n\n# Customize plot\nax.set_axis_off()\n\n# Show map\nplt.show()\n\n\n\npng\n\n\n# Calculate Moran's I\nmi = esda.Moran(final_df['GWR_residuals'], w_queen)\n# I value\nprint(f'I value: {mi.I}')\n\n# Significance (p value)\nprint(f'P value: {mi.p_sim}')\n\n\n\nI value\n0.23403007956028024\n\n\n\n\nP value\n0.001"
  },
  {
    "objectID": "projects/access-to-greenspace/access-to-greenspace-bradford.html#discussion",
    "href": "projects/access-to-greenspace/access-to-greenspace-bradford.html#discussion",
    "title": "A spatial analysis of access to greenspace and deprivation in Bradford",
    "section": "8. Discussion",
    "text": "8. Discussion\nResults showed deprivation and distance to greenspace are negatively correlated, reflecting much of the literature, and rejects the null hypothesis posed. However, the relationship differs by dimension and spatially. Any policy or intervention needs to consider this.\nKey differentiators of this study are using deprivation dimensions and OA geographies, attempting to consider distance at a local level appropriate to the Natural England (2023) targets. However, there are limitations and opportunities for improvement.\nFirstly, not all greenspace is considered. Many woodlands, moorlands, river and canal paths are not included but are publicly accessible. Including this would better reflect true greenspace but would also raise consideration of type. Different greenspace serves different purposes – for example, a children’s park versus unmaintained moorland – and so understanding access to different types may further unlock insight into what is within an accessible distance and for whom.\nSecondly, the distance calculation could be improved. Utilising address data to estimate household locations, alongside road and path networks, would allow more accurate calculation of distance to greenspace. This could be an average walk time which would align better to Natural England (2023) targets.\nLastly, two limitations identified in the literature remain: quality and usage. Quality can be subjective and dependent on the greenspace’s purpose. However, a survey recording facilities, amenities, and biodiversity could develop a qualitative understanding. The Natural Environment Scoring Tool (NEST) used in Ferguson et al’s (2018) study provides a starting point. Technological advancements could improve usage data, such as GPS which was used by Mears et al (2021), however data protection, scale, and availability challenges exist.\nDespite these limitations, actions could result from the findings. Deprivation differs by dimension and policy needs to consider this, as well as communities and their needs. These needs will vary by area. This is supported by research conducted on community perceptions (McEachan et al, 2018), highlighting the importance of including communities in decision-making processes.\nFinally, two areas of future research are identified. Firstly, including a broader set of demographic measures beyond deprivation. Age and ethnicity are key, as shown in the literature, but no research addressed in this study has considered variables such as profession which could have an impact on how and when someone accesses greenspace. Secondly, there is opportunity to reflect on the impact of new greenspace, or improvements to current greenspace, to learn and adapt plans. CBMDC (2021) have clear goals they wish to achieve, but understanding the effectiveness of interventions is needed to ensure investments add value. Deprivation can be a relatively slow to change measure. Further studies analysing more reactive variables may enable a comprehensive review of what works in different communities."
  },
  {
    "objectID": "projects/access-to-greenspace/access-to-greenspace-bradford.html#conclusion",
    "href": "projects/access-to-greenspace/access-to-greenspace-bradford.html#conclusion",
    "title": "A spatial analysis of access to greenspace and deprivation in Bradford",
    "section": "9. Conclusion",
    "text": "9. Conclusion\nThis study sought to build on previous research into the relationship between distance to greenspace and deprivation by splitting deprivation into the component dimensions. The findings mirror the literature that there is a statistically significant, negative correlation between distance to greenspace and deprivation, but the use of dimensions and understanding this spatially has shown that the results vary by area. Policy implications are that decisions should be on a local scale, and interventions may vary depending on the community and their needs.\nHowever, this is not only tied to deprivation and this study has argued that a more holistic view of demographics within communities is required, and consideration for the type of greenspace and its uses. This will allow planners to develop better suited solutions to improve community health and wellbeing, with greenspace that meets the needs and wants of the communities they serve."
  },
  {
    "objectID": "projects/access-to-greenspace/access-to-greenspace-bradford.html#references",
    "href": "projects/access-to-greenspace/access-to-greenspace-bradford.html#references",
    "title": "A spatial analysis of access to greenspace and deprivation in Bradford",
    "section": "References",
    "text": "References\nBarbosa, O., Tratalos. J.A., Armsworth, P.R., Davies, R.G., Fuller, R.A., Johnson, P. and Gaston, K.J. 2007. Who benefits from access to green space? A case study from Sheffield, UK. Landscape and Urban Planning. 83(2-3), pp. 187-195.\nCity of Bradford Metropolitan District Council (CBMDC). 2019. Public Health - Joint Strategic Needs Assessment. [Online]. Bradford: City of Bradford Metropolitan District Council. [Accessed 09 January 2024]. Available from: https://jsna.bradford.gov.uk/\nCity of Bradford Metropolitan District Council (CBMDC). 2021. Our Council Plan: Priorities and Principles 2021-2025. [Online]. Bradford: City of Bradford Metropolitan District Council. [Accessed 09 January 2024]. Available from: https://www.bradford.gov.uk/media/6508/bradfordcouncilplan.pdf\nCity of Bradford Metropolitan District Council (CBMDC). 2022. 2021 Census: Bradford District. [Online]. [Accessed 09 January 2024]. Available from: https://ubd.bradford.gov.uk/about-us/2021-census/\nFerguson, M., Roberts, H.E., McEachan, R.R.C. and Dallimer, M. 2018. Contrasting distributions of urban green infrastructure across social and ethno-racial groups. Landscape and Urban Planning. 175, pp.136-148.\nGidlow, C.J. and Ellis, N.J. 2011. Neighbourhood green space in deprived urban communities: issues and barriers to use. The International Journal of Justice and Sustainability. 16(10), pp.989-1002.\nHoulden, V., Porto de Albuquerque, J., Weich, S. and Jarvis, S. 2019. A spatial analysis of proximate greenspace and mental wellbeing in London. Applied Geography. 109, pp.102036.\nJia, P., Cao, X., Yang, H., Dai, S., He, P., Huang, G., Wu, T. and Wang, Y. 2021. Green space access in the neighbourhood and childhood obesity. Obesity Reviews. 22(51), pp.13100.\nJones, A., Hillsdon, M. and Coombes, E. 2009. Greenspace access, use, and physical activity: Understanding the effects of area deprivation. Preventive Medicine. 49(6), pp.500-505.\nKessel, A., Green, J., Pinder, R., Wilkinson, P., Grundy, C. and Lachowycz, K. 2009. Multidisciplinary research in public health: A case study of research on access to green space. Public Health. 123(1), pp.32-38.\nLachowycz, K. and Jones, A.P. 2011. Greenspace and obesity: a systematic review of the evidence. Obesity Reviews. 12(5), pp.183-189.\nMcCormick, R. 2017. Does Access to Green Space Impact the Mental Well-being of Children: A Systematic Review. Journal of Pediatric Nursing. 37, pp.3-7.\nMcEachan, R.R.C., Yang, T.C., Roberts, H., Pickett, K.E., Arseneau-Powell, D., Gidlow, C.J., Wright, J. and Nieuwenhuijsen, M. 2018. Availability, use of, and satisfaction with green space, and children’s mental wellbeing at age 4 years in a multicultural, deprived, urban area: results from the Born in Bradford cohort study. The Lancet Planetary Health. 2(6), pp.244-254.\nMears, M., Brindley, P., Barrows, P., Richardson, M. and Maheswaran, R. 2021. Mapping urban greenspace use from mobile phone GPS data. PLoS ONE. 16(7), pp.0248622.\nMears, M., Brindley, P., Maheswaran, R. and Jorgensen, A. 2019. Understanding the socioeconomic equity of publicly accessible greenspace distribution: The example of Sheffield, UK. Geoforum. 103, pp.126-137.\nMueller, N., Rojas-Rueda, D., Khreis, H., Cirach, M., Milà, C., Espinosa, A., Foraster, M., McEachan, R.R.C., Kelly, B., Wright, J. and Nieuwenhuijsen, M. 2018. Socioeconomic inequalities in urban and transport planning related exposures and mortality: A health impact assessment study for Bradford, UK. Environment International. 121(1), pp.931-941.\nNatural England. 2023. Natural England unveils new Green Infrastructure Framework. [Press release]. [Accessed 09 January 2024]. Available from: https://www.gov.uk/government/news/natural-england-unveils-new-green-infrastructure-framework\nOffice for National Statistics (ONS). 2021. Census 2021 geographies. [Online]. [Accessed 09 January 2024]. Available from: https://www.ons.gov.uk/methodology/geography/ukgeographies/censusgeographies/census2021geographies\nOffice for National Statistics (ONS). 2023a. Output Areas (2021) Boundaries EW BFC. Open Geography Portal. [Online]. [Accessed 11 December 2023]. Available from: https://geoportal.statistics.gov.uk/datasets/ons::output-areas-2021-boundaries-ew-bfc/about\nOffice for National Statistics (ONS). 2023b. Output Areas (December 2021) PWC (V3). Open Geography Portal. [Online]. [Accessed 11 December 2023]. Available from: https://geoportal.statistics.gov.uk/datasets/ons::output-areas-december-2021-pwc-v3/about\nOffice for National Statistics (ONS). 2023c. Output Area to Lower layer Super Output Area to Middle layer Super Output Area to Local Authority District (December 2021) Lookup in England and Wales V2. Open Geography Portal. [Online]. [Accessed 14 December 2023]. Available from: https://geoportal.statistics.gov.uk/datasets/output-area-to-lower-layer-super-output-area-to-middle-layer-super-output-area-to-local-authority-district-december-2021-lookup-in-england-and-wales-v2-1/about\nOffice for National Statistics (ONS). 2023d. Household deprivation in the education dimension. Office for National Statistics. [Online]. [Accessed 14 December 2023]. Available from: https://www.ons.gov.uk/filters/d7bede85-c97b-4b85-84a8-87b5164d3add/dimensions\nOffice for National Statistics (ONS). 2023e. Household deprivation in the employment dimension. Office for National Statistics. [Online]. [Accessed 14 December 2023]. Available from: https://www.ons.gov.uk/filters/103a7748-96d9-4e79-97e2-e1cc42ef7024/dimensions\nOffice for National Statistics (ONS). 2023f. Household deprivation in the health dimension. Office for National Statistics. [Online]. [Accessed 14 December 2023]. Available from: https://www.ons.gov.uk/filters/15149637-c729-4aa5-b817-d687cad093d8/dimensions\nOffice for National Statistics (ONS). 2023g. Household deprivation in the housing dimension. Office for National Statistics. [Online]. [Accessed 14 December 2023]. Available from: https://www.ons.gov.uk/filters/cf7beddc-198f-411a-9b66-9c690d18e3bf/dimensions\nOffice for National Statistics (ONS). 2023h. How life has changed in Bradford: Census 2021. [Online]. [Accessed 09 January 2024]. Available from: https://www.ons.gov.uk/visualisations/censusareachanges/E08000032/\nOffice for National Statistics (ONS). 2023i. Rising ill-health and economic inactivity because of long-term sickness, UK: 2019 to 2023. [Online]. [Accessed 11 January 2024]. Available from: https://rb.gy/bsf8hg\nOrdnance Survey (OS). 2023. OS Open Greenspace. Ordnance Survey. [Online]. [Accessed 6 December 2023]. Available from: https://osdatahub.os.uk/downloads/open/OpenGreenspace\nPaez, A. and Scott, D.M. 2004. Spatial statistics for urban analysis: A review of techniques with examples. GeoJournal. 61, pp.53-67.\nRoe, J., Aspinall, P.A. and Thompson, C.W. 2016. Understanding Relationships between Health, Ethnicity, Place and the Role of Urban Green Space in Deprived Urban Communities. International Journal of Environmental Research and Public Health. 13(7), pp.681.\nWood, E., Harsant, A., Dallimer, M., Cronin de Chavez, A., McEachan, R.R.C. and Hassall, C. 2018. Not All Green Space Is Created Equal: Biodiversity Predicts Psychological Restorative Benefits From Urban Green Space. Frontiers in Psychology. 9, pp2320."
  },
  {
    "objectID": "projects/access-to-greenspace/access-to-greenspace-bradford.html#appendix-1---wrangled-dataframes",
    "href": "projects/access-to-greenspace/access-to-greenspace-bradford.html#appendix-1---wrangled-dataframes",
    "title": "A spatial analysis of access to greenspace and deprivation in Bradford",
    "section": "Appendix 1 - Wrangled dataframes",
    "text": "Appendix 1 - Wrangled dataframes\nThis appendix contains visual checks of the top five rows of the wrangled dataframes created in section 5.\n\nBradford OA polygons dataframe\nBradford_OA_polygons.head()\n\n\n\n\n\n\nOA21CD\n\n\nPolygon\n\n\nCity\n\n\n\n\n\n\n0\n\n\nE00053353\n\n\nPOLYGON ((415817.093 440872.597, 415821.094 44…\n\n\nBradford\n\n\n\n\n1\n\n\nE00053354\n\n\nPOLYGON ((415078.000 439967.001, 415058.323 43…\n\n\nBradford\n\n\n\n\n2\n\n\nE00053355\n\n\nPOLYGON ((416252.367 439816.041, 416253.270 43…\n\n\nBradford\n\n\n\n\n3\n\n\nE00053356\n\n\nPOLYGON ((416668.000 439392.028, 416667.653 43…\n\n\nBradford\n\n\n\n\n4\n\n\nE00053357\n\n\nPOLYGON ((415143.909 439176.235, 415143.000 43…\n\n\nBradford\n\n\n\n\n\n\nBradford OA population weighted centroids dataframe\nBradford_OA_PWC.head()\n\n\n\n\n\n\nOA21CD\n\n\nPWC\n\n\n\n\n\n\n0\n\n\nE00053353\n\n\nPOINT (413638.052 439495.615)\n\n\n\n\n1\n\n\nE00053354\n\n\nPOINT (414837.013 439813.246)\n\n\n\n\n2\n\n\nE00053355\n\n\nPOINT (416162.559 439674.009)\n\n\n\n\n3\n\n\nE00053356\n\n\nPOINT (416591.137 439417.227)\n\n\n\n\n4\n\n\nE00053357\n\n\nPOINT (414671.681 439110.823)\n\n\n\n\n\n\nBradford greenspace polygons (unique list)\nBradford_greenspace_site_unique.head()\n\n\n\n\n\n\nGreenspace_ID\n\n\nType\n\n\nPolygon\n\n\n\n\n\n\n0\n\n\n0295ED18-D538-5C37-E063-AAEFA00A445E\n\n\nPlaying Field\n\n\nPOLYGON Z ((414018.070 438415.690 0.000, 41399…\n\n\n\n\n1\n\n\n0295ED18-E5D4-5C37-E063-AAEFA00A445E\n\n\nPlaying Field\n\n\nPOLYGON Z ((415193.700 439129.550 0.000, 41519…\n\n\n\n\n2\n\n\n0295ED18-F2F3-5C37-E063-AAEFA00A445E\n\n\nPlaying Field\n\n\nPOLYGON Z ((415690.440 439919.060 0.000, 41568…\n\n\n\n\n3\n\n\n0295ECC9-0C25-5C37-E063-AAEFA00A445E\n\n\nPlay Space\n\n\nPOLYGON Z ((416739.570 439592.210 0.000, 41675…\n\n\n\n\n4\n\n\n0295ECC7-FBFC-5C37-E063-AAEFA00A445E\n\n\nPlay Space\n\n\nPOLYGON Z ((415991.960 438808.610 0.000, 41598…\n\n\n\n\n\n\nNearest greenspace to each OA (unique list)\nunique_nearest_greenspace.head()\n\n\n\n\n\n\nOA21CD\n\n\nGreenspace_ID\n\n\nType\n\n\nDistance\n\n\n\n\n\n\n0\n\n\nE00053353\n\n\n0295ED18-D538-5C37-E063-AAEFA00A445E\n\n\nPlaying Field\n\n\n1000.455806\n\n\n\n\n1\n\n\nE00053354\n\n\n0295ED18-E5D4-5C37-E063-AAEFA00A445E\n\n\nPlaying Field\n\n\n771.145845\n\n\n\n\n2\n\n\nE00053355\n\n\n0295ED18-F2F3-5C37-E063-AAEFA00A445E\n\n\nPlaying Field\n\n\n418.265674\n\n\n\n\n3\n\n\nE00053356\n\n\n0295ECC9-0C25-5C37-E063-AAEFA00A445E\n\n\nPlay Space\n\n\n194.292561\n\n\n\n\n4\n\n\nE00053357\n\n\n0295ED18-E5D4-5C37-E063-AAEFA00A445E\n\n\nPlaying Field\n\n\n432.352481\n\n\n\n\n\n\nIndependent variables dataframe\nInd_vars.head()\n\n\n\n\n\n\nOutput Areas Code\n\n\nHHD_dep_education_PC\n\n\nHHD_dep_employment_PC\n\n\nHHD_dep_health_PC\n\n\nHHD_dep_housing_PC\n\n\n\n\n\n\n0\n\n\nE00053353\n\n\n28.3\n\n\n11.5\n\n\n33.6\n\n\n7.8\n\n\n\n\n1\n\n\nE00053354\n\n\n17.3\n\n\n6.8\n\n\n30.8\n\n\n5.3\n\n\n\n\n2\n\n\nE00053355\n\n\n11.2\n\n\n4.9\n\n\n22.0\n\n\n1.6\n\n\n\n\n3\n\n\nE00053356\n\n\n21.5\n\n\n4.2\n\n\n34.0\n\n\n4.9\n\n\n\n\n4\n\n\nE00053357\n\n\n14.2\n\n\n3.5\n\n\n21.3\n\n\n0.7"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hello, I’m Jess!",
    "section": "",
    "text": "🔍 I’m an insight and analytics specialist with nearly a decade of experience across lots of different roles and sectors.\n🧩 I mainly work with geospatial data, and solve problems to help people make better decisions.\n\n\n\n⏯️ In September 2023 I decided to take a career break and explore new opportunities.\n👩‍🎓 I’m currently pursuing an MSc in Urban Data Science & Analytics at the University of Leeds, whilst working as a Freelance Consultant.\n💡 My studies have deepened my analytical and research capabilities whilst giving me the time and space to delve into all things geospatial!\n\n\n\n\n\n\n🌱 My aim is to move into sustainable development and use my skills and expertise to help solve problems in our cities.\n\n\nYou can find me on GitHub and LinkedIn here:"
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "Hello, I’m Jess!",
    "section": "",
    "text": "🔍 I’m an insight and analytics specialist with nearly a decade of experience across lots of different roles and sectors.\n🧩 I mainly work with geospatial data, and solve problems to help people make better decisions."
  },
  {
    "objectID": "index.html#what-im-currently-doing",
    "href": "index.html#what-im-currently-doing",
    "title": "Hello, I’m Jess!",
    "section": "",
    "text": "⏯️ In September 2023 I decided to take a career break and explore new opportunities.\n👩‍🎓 I’m currently pursuing an MSc in Urban Data Science & Analytics at the University of Leeds, whilst working as a Freelance Consultant.\n💡 My studies have deepened my analytical and research capabilities whilst giving me the time and space to delve into all things geospatial!"
  },
  {
    "objectID": "index.html#what-do-i-want-to-do",
    "href": "index.html#what-do-i-want-to-do",
    "title": "Hello, I’m Jess!",
    "section": "",
    "text": "🌱 My aim is to move into sustainable development and use my skills and expertise to help solve problems in our cities.\n\n\nYou can find me on GitHub and LinkedIn here:"
  },
  {
    "objectID": "projects/access-to-greenspace/index.html",
    "href": "projects/access-to-greenspace/index.html",
    "title": "A spatial analysis of access to greenspace and deprivation in Bradford",
    "section": "",
    "text": "The full study can be found here or you can go back to see more projects.\n\n\nSummary\nGreenspace is an important part of urban life, with benefits for humans and the environment. Analysing Bradford local authority district, this study builds on the growing literature addressing the challenge of greenspace accessibility by focusing on each deprivation dimension recorded in the 2021 Census.\nBradford is a large district, with a young and diverse population. Health and housing inequalities are known issues, whilst greenspace varies across the district in terms of quantity, type and size. The council has embedded greenspace within its long-term strategy, aiming to make sure they are safe, inclusive and that investment is delivered where it is needed most.\nThis study brings together 2021 Census data on each dimension of deprivation (education, employment, health and housing) by Output Area (OA), and combines this with Ordanance Survey data on greenspace in the district. After some initial data wrangling, a series of statistics and visualisations help to illustrate the data that will be used in the subsequent modelling.\nFirst, using an OLS regression model, the variables are analysed to understand the significance of their relationship with access to greenspace - defined here as the distance to the nearest greenspace. This shows that employment deprivation is not statistically significant, and is subsequently removed.\nFurther investigation using a range of techniques, including Moran’s I and LISA clusters, shows that there is spatial autocorrelation present and so a Geographically Weighted Regression model (GWR) is built. The results of this reject the null hypothesis that there is not a statistically significant relationship present between dimensions of deprivation and access to greenspace.\nThis study therefore argues that any future policy interventions need to take into consideration deprivation and its relationship with greenspace.\n\n\n\nDisclaimer\nThis notebook was submitted for assessment within the GEOG5402 Data Science for Urban Systems module as part of the MSc Urban Data Science & Analytics programme at the University of Leeds.\nThe content of this notebook is intended for educational and general use purposes only.\nAny use of the materials should adhere to the guidelines and policies of your educational institution.\nThe author does not take any responsibility for how the materials in this repository are utilised."
  },
  {
    "objectID": "projects/20min_neighbourhoods/index.html",
    "href": "projects/20min_neighbourhoods/index.html",
    "title": "20-minute neighbourhoods: understanding housing density in Bradford",
    "section": "",
    "text": "Go back to the projects page."
  },
  {
    "objectID": "projects/20min_neighbourhoods/index.html#disclaimer",
    "href": "projects/20min_neighbourhoods/index.html#disclaimer",
    "title": "20-minute neighbourhoods: understanding housing density in Bradford",
    "section": "Disclaimer",
    "text": "Disclaimer\nThis analysis was part of a larger piece of work on 20-minute neighbourhoods as part of the GEOG5403 Creative Coding for Urban Problems module on the MSc Urban Data Science & Analytics programme at the University of Leeds.\nThe content of this notebook is intended for educational and general use purposes only.\nAny use of the materials should adhere to the guidelines and policies of your educational institution.\nThe author does not take any responsibility for how the materials in this repository are utilised."
  },
  {
    "objectID": "projects/20min_neighbourhoods/index.html#summary",
    "href": "projects/20min_neighbourhoods/index.html#summary",
    "title": "20-minute neighbourhoods: understanding housing density in Bradford",
    "section": "Summary",
    "text": "Summary\nIn a 20-minute neighbourhood, residents can walk, wheel or cycle to key services and amenities within a return 20-minute journey. The concept is not new, but interest grew as COVID-19 lockdowns highlighted the liveability of local areas. One way to identify a 20-minute neighbourhood is to draw a suitable walk-time around an area, analyse what services exist, and then “fill in the gaps”. However, this approach does not consider wants and needs of local communities and how this can differ. The Town and Country Planning Association has built a comprehensive guide arguing most 20-minute neighbourhoods will include many similar features, like schools, greenspaces, and health facilities.\nThis analysis looks at potential 20-minute neighbourhoods in Bradford, with the aim of understanding housing density to determine where people live and therefore which areas might have the most households benefit from investment in the 20-minute neighbourhood concept.\nUsing population-weighted centroids (PWCs) for each output area (OA), an 800m Euclidian buffer is drawn around this point to reflect 20-minute neighbourhoods, as shown in Figure 1. OAs are the smallest census geography, with PWCs reflecting where people live compared to the centre-point of the polygon. However, OA polygons are used to visualise results for clarity, avoiding buffer overlap.\nFigure 1: Defining neighbourhoods\n\nFor housing, OA populations could have been used but would include everyone in any OA with a PWC inside the neighbourhood buffer, rather than the households within the neighbourhood itself. Instead, domestic EPC ratings since 2008 are used to find residential properties, spatially matching these to the buffers. Over 157,000 homes were identified, roughly 75% coverage given 210,000 households in Bradford.\nClear spatial patterns emerge of where housing is most dense, with these areas potentially being good candidates to investigate further in terms how well they are or are not setup for 20-minute living. There are limitations to this methodology, including:\n\n800m Euclidian buffers not reflecting actual path networks - a network analysis may be more useful in reflecting true 20-minute neighbourhoods\nPopulation is not included, and so the actual number of people living in these neighbourhoods is not calculated\n\nFigure 2: Housing density choropleth"
  },
  {
    "objectID": "projects/20min_neighbourhoods/index.html#import-and-setup-geographies",
    "href": "projects/20min_neighbourhoods/index.html#import-and-setup-geographies",
    "title": "20-minute neighbourhoods: understanding housing density in Bradford",
    "section": "Import and setup geographies",
    "text": "Import and setup geographies\nLinks to the raw data can be found in each code cell. OA data needs to be reduced to just Bradford, and then dataframes tidied ready for use.\n# Import required libraries\nimport pandas as pd\nimport geopandas as gpd\n# OA polygons (BFC: Full resolution - clipped to the coastline (Mean High Water mark))\n# https://geoportal.statistics.gov.uk/datasets/ons::output-areas-2021-boundaries-ew-bfc/about\nOA_polygons = gpd.read_file('Data/Output_Areas_2021_Polygon/OA_2021_EW_BFC_V8.shp')\n\n# OA Population-weighted centroids\n# https://geoportal.statistics.gov.uk/datasets/ons::output-areas-december-2021-pwc-v3/about\nOA_PWC = gpd.read_file('Data/Output_Areas_2021_Centroid/PopCentroids_EW_2021_V3.shp')\n# OA to LSOA to MSOA to LAD lookup\n# https://geoportal.statistics.gov.uk/datasets/output-area-to-lower-layer-super-output-area-to-middle-layer-super-output-area-to-local-authority-district-december-2021-lookup-in-england-and-wales-v2-1/about\nOA_lookup = pd.read_csv('Data/Output_Area_Lookup_in_England_and_Wales_v3.csv')\n# Remove unnecessary columns from OA lookup, keeping only required columns in new dataframe\nOA_lookup_trim = OA_lookup[['OA21CD','LAD22CD','LAD22NM']]\n# Filter OA lookup to just Bradford\nBradford_OA_lookup = OA_lookup_trim[OA_lookup_trim['LAD22NM'] == 'Bradford']\n# Check how many OAs are left - this number is an important reference point for further data wrangling tasks\nlen(Bradford_OA_lookup)\n1575\n# Merge Bradford_OA_lookup with OA polygons to reduce the geodataframe containing the polygons to only Bradford OAs\nBradford_OA_polygons = OA_polygons.merge(Bradford_OA_lookup, how='right', on='OA21CD')\n# Check number of OAs is same as in the reduced Bradford OA lookup dataframe\nprint(len(Bradford_OA_polygons))\nprint(len(Bradford_OA_polygons) == len(Bradford_OA_lookup))\n1575\nTrue\n# Merge Bradford_OA_lookup with OA PWCs to reduce the geodataframe containing the PWCs to only Bradford OAs\nBradford_OA_PWC = OA_PWC.merge(Bradford_OA_lookup, how='right', on='OA21CD')\n# Check number of OAs is same as in the reduced Bradford OA lookup dataframe\nprint(len(Bradford_OA_PWC))\nprint(len(Bradford_OA_PWC) == len(Bradford_OA_lookup))\n1575\nTrue\n# Drop unrequired columns\nBradford_OA_polygons_tidy = Bradford_OA_polygons.drop([\n    'LSOA21CD','LSOA21NM','LSOA21NMW','BNG_E','BNG_N','LAT','LONG','GlobalID','LAD22CD','LAD22NM'], axis=1)\nBradford_OA_PWC_tidy = Bradford_OA_PWC.drop(['GlobalID','LAD22CD','LAD22NM'], axis=1)\n\n# Rename geometry columns and set geometry\nBradford_OA_polygons = Bradford_OA_polygons_tidy.set_geometry('geometry').rename_geometry('Polygon')\nBradford_OA_PWC = Bradford_OA_PWC_tidy.set_geometry('geometry').rename_geometry('PWC')"
  },
  {
    "objectID": "projects/20min_neighbourhoods/index.html#build-20-minute-neighbourhoods-using-800m-euclidian-buffer",
    "href": "projects/20min_neighbourhoods/index.html#build-20-minute-neighbourhoods-using-800m-euclidian-buffer",
    "title": "20-minute neighbourhoods: understanding housing density in Bradford",
    "section": "Build 20-minute neighbourhoods using 800m Euclidian buffer",
    "text": "Build 20-minute neighbourhoods using 800m Euclidian buffer\nAs highlighted in the summary, an 800m Euclidian buffer around each PWC will be used to act as the 20-minute neighbourhoods.\n# Import required libraries\nfrom shapely.geometry import Point\n# Function to create a buffer around a point with a given radius\ndef create_buffer(point, radius):\n    return point.buffer(radius)\n\n# Define the radius of the circle (in meters)\nradius_meters = 800\n\n# Create a new column in the GeoDataFrame to store the buffer polygons\nBradford_OA_PWC['buffer'] = Bradford_OA_PWC['PWC'].apply(lambda point: create_buffer(point, radius_meters))\n\n# Now, 'buffer' column contains the buffer polygons around each point with a radius of 800 meters\n# Set the 'buffer' to be the geometry\nBradford_OA_PWC.set_geometry('buffer', inplace=True)"
  },
  {
    "objectID": "projects/20min_neighbourhoods/index.html#get-locations-of-residential-properties",
    "href": "projects/20min_neighbourhoods/index.html#get-locations-of-residential-properties",
    "title": "20-minute neighbourhoods: understanding housing density in Bradford",
    "section": "Get locations of residential properties",
    "text": "Get locations of residential properties\nTo obtain the location of the houses, EPC ratings since 2008 is combined with UPRN point data. Properties might have multiple EPC ratings, and so the data must be ordered newest to oldest, and duplicates removed keeping only the latest rating. The EPC ratings can then be merged with the UPRN data to obtain the point of each property, setting this as the geometry for further analysis.\n\nEPC ratings\n# EPC Ratings\n# https://epc.opendatacommunities.org/\nEPC_Ratings = pd.read_csv('Data/Housing/domestic-E08000032-Bradford/certificates.csv')\n# Step 1: Sort by date column in descending order\nEPC_sorted = EPC_Ratings.sort_values(by='LODGEMENT_DATETIME', ascending=False)\n\n# Step 2: Remove duplicates keeping the first instance based on 'UPRN' column\nEPC_unique = EPC_sorted.drop_duplicates(subset='UPRN', keep='first')\n# Check how properties are in the dataframe\nlen(EPC_unique)\n157255\n\n\nUPRNs\n# UPRNs\n# https://osdatahub.os.uk/downloads/open/OpenUPRN\nUPRNs = pd.read_csv('Data/Housing/osopenuprn_202404_csv/osopenuprn_202404.csv')\nUPRNs.head()\n\n\n\n\n\n\nUPRN\n\n\nX_COORDINATE\n\n\nY_COORDINATE\n\n\nLATITUDE\n\n\nLONGITUDE\n\n\n\n\n\n\n0\n\n\n1\n\n\n358260.66\n\n\n172796.5\n\n\n51.452601\n\n\n-2.602075\n\n\n\n\n1\n\n\n26\n\n\n352967.00\n\n\n181077.0\n\n\n51.526633\n\n\n-2.679361\n\n\n\n\n2\n\n\n27\n\n\n352967.00\n\n\n181077.0\n\n\n51.526633\n\n\n-2.679361\n\n\n\n\n3\n\n\n30\n\n\n354800.00\n\n\n180469.0\n\n\n51.521317\n\n\n-2.652862\n\n\n\n\n4\n\n\n31\n\n\n354796.00\n\n\n180460.0\n\n\n51.521236\n\n\n-2.652918\n\n\n\n\n\n\nMerge the two dataframes\n# Merge EPC Ratings and UPRNs\nMatched = EPC_unique.merge(UPRNs, how='inner', on='UPRN')\n# Keep only columns required for analysis\nMatched_trim = Matched[['UPRN','LATITUDE','LONGITUDE']].copy()\n# Convert the Latitude and Longitude columns into Point objects\ngeometry = [Point(xy) for xy in zip(Matched_trim['LONGITUDE'], Matched_trim['LATITUDE'])]\n\n# Convert to a GeoDataFrame\nMatched_final = gpd.GeoDataFrame(Matched_trim, geometry=geometry).set_crs('epsg:4326')\n# Change crs to match other data\nMatched_final = Matched_final.to_crs(27700)\nMatched_final.head()\n\n\n\n\n\n\nUPRN\n\n\nLATITUDE\n\n\nLONGITUDE\n\n\ngeometry\n\n\n\n\n\n\n0\n\n\n1.000512e+11\n\n\n53.763624\n\n\n-1.768966\n\n\nPOINT (415327.798 429721.658)\n\n\n\n\n1\n\n\n1.000512e+11\n\n\n53.801380\n\n\n-1.826545\n\n\nPOINT (411521.815 433911.593)\n\n\n\n\n2\n\n\n1.000512e+11\n\n\n53.802175\n\n\n-1.829245\n\n\nPOINT (411343.819 433999.592)\n\n\n\n\n3\n\n\n1.000512e+11\n\n\n53.781098\n\n\n-1.816461\n\n\nPOINT (412191.822 431656.624)\n\n\n\n\n4\n\n\n1.009167e+10\n\n\n53.823379\n\n\n-1.860954\n\n\nPOINT (409250.808 436354.194)\n\n\n\n\nlen(Matched_final)\n157252\n# Check length of the final dataframe is the same as the unique properties that were found\nlen(Matched_final) == len(EPC_unique)\nFalse\n# Check the difference to see how many properties in the EPC ratings did NOT match a UPRN (this could be because they were missing or entered incorrectly)\nlen(Matched_final) - len(EPC_unique)\n-3"
  },
  {
    "objectID": "projects/20min_neighbourhoods/index.html#mapping-properties",
    "href": "projects/20min_neighbourhoods/index.html#mapping-properties",
    "title": "20-minute neighbourhoods: understanding housing density in Bradford",
    "section": "Mapping properties",
    "text": "Mapping properties\nA quick map illustrates where the properties are located.\n# Import required libraries\nimport contextily as cx\nimport matplotlib.pyplot as plt\n# Plotting the GeoDataFrame with basemap\nax = Matched_final.plot(figsize=(10, 6), markersize=10, color='red')\n\n# Add basemap using contextily\ncx.add_basemap(ax, zoom=12, crs=Matched_final.crs.to_string())\n\n# Set title\nplt.title('Properties identified by EPC data')\n\n# Turn off the axes\nax.axis('off')\n\nplt.show()"
  },
  {
    "objectID": "projects/20min_neighbourhoods/index.html#spatially-match-properties-to-neighbourhood-buffers",
    "href": "projects/20min_neighbourhoods/index.html#spatially-match-properties-to-neighbourhood-buffers",
    "title": "20-minute neighbourhoods: understanding housing density in Bradford",
    "section": "Spatially match properties to neighbourhood buffers",
    "text": "Spatially match properties to neighbourhood buffers\nNext the properties can be spatially matched to the neighbourhood buffers to determine how many properties are in each neighbourhood. It is important to reiterate that this EPC rating methodology has roughly 75% coverage of all households, and does not include actual population counts which could vary depending on size of property.\n# Make a copy of the dataframe containing the buffers with only the required columns\nBradford_PWC_buffers = Bradford_OA_PWC[['OA21CD','buffer']].copy()\n# Spatially match the properties to the buffers\njoined = Bradford_PWC_buffers.sjoin(Matched_final, how=\"left\", predicate=\"intersects\")\n# Visual check of the dataframe - there are duplicated rows due to the overlap of some neighbourhood buffer zones\njoined\n\n\n\n\n\n\nOA21CD\n\n\nbuffer\n\n\nindex_right\n\n\nUPRN\n\n\nLATITUDE\n\n\nLONGITUDE\n\n\n\n\n\n\n0\n\n\nE00053353\n\n\nPOLYGON ((414438.052 439495.615, 414434.200 43…\n\n\n35797\n\n\n1.000519e+11\n\n\n53.847941\n\n\n-1.784022\n\n\n\n\n0\n\n\nE00053353\n\n\nPOLYGON ((414438.052 439495.615, 414434.200 43…\n\n\n63910\n\n\n2.000047e+11\n\n\n53.848048\n\n\n-1.783626\n\n\n\n\n0\n\n\nE00053353\n\n\nPOLYGON ((414438.052 439495.615, 414434.200 43…\n\n\n58772\n\n\n1.000513e+11\n\n\n53.845011\n\n\n-1.789341\n\n\n\n\n0\n\n\nE00053353\n\n\nPOLYGON ((414438.052 439495.615, 414434.200 43…\n\n\n11651\n\n\n1.000513e+11\n\n\n53.845155\n\n\n-1.789355\n\n\n\n\n0\n\n\nE00053353\n\n\nPOLYGON ((414438.052 439495.615, 414434.200 43…\n\n\n157213\n\n\n1.000513e+11\n\n\n53.845362\n\n\n-1.789309\n\n\n\n\n…\n\n\n…\n\n\n…\n\n\n…\n\n\n…\n\n\n…\n\n\n…\n\n\n\n\n1574\n\n\nE00177810\n\n\nPOLYGON ((410759.264 435503.188, 410755.412 43…\n\n\n119131\n\n\n1.009098e+10\n\n\n53.821992\n\n\n-1.855611\n\n\n\n\n1574\n\n\nE00177810\n\n\nPOLYGON ((410759.264 435503.188, 410755.412 43…\n\n\n50374\n\n\n1.000519e+11\n\n\n53.816365\n\n\n-1.848081\n\n\n\n\n1574\n\n\nE00177810\n\n\nPOLYGON ((410759.264 435503.188, 410755.412 43…\n\n\n31264\n\n\n1.000519e+11\n\n\n53.816429\n\n\n-1.848704\n\n\n\n\n1574\n\n\nE00177810\n\n\nPOLYGON ((410759.264 435503.188, 410755.412 43…\n\n\n100903\n\n\n1.000519e+11\n\n\n53.816465\n\n\n-1.848628\n\n\n\n\n1574\n\n\nE00177810\n\n\nPOLYGON ((410759.264 435503.188, 410755.412 43…\n\n\n154452\n\n\n1.000233e+10\n\n\n53.816501\n\n\n-1.848430\n\n\n\n\n\n3703801 rows × 6 columns\n\n# Group by OA21CD and count the unique UPRNs\nagg_df = joined.groupby('OA21CD')['UPRN'].nunique().reset_index()\n\n# Rename the column to indicate the count of UPRNs\nagg_df.rename(columns={'UPRN': 'UPRN_Count'}, inplace=True)\n# Visual check\nagg_df\n\n\n\n\n\n\nOA21CD\n\n\nUPRN_Count\n\n\n\n\n\n\n0\n\n\nE00053353\n\n\n214\n\n\n\n\n1\n\n\nE00053354\n\n\n1148\n\n\n\n\n2\n\n\nE00053355\n\n\n1405\n\n\n\n\n3\n\n\nE00053356\n\n\n965\n\n\n\n\n4\n\n\nE00053357\n\n\n1441\n\n\n\n\n…\n\n\n…\n\n\n…\n\n\n\n\n1570\n\n\nE00177867\n\n\n3780\n\n\n\n\n1571\n\n\nE00177868\n\n\n2910\n\n\n\n\n1572\n\n\nE00177869\n\n\n5265\n\n\n\n\n1573\n\n\nE00177870\n\n\n2096\n\n\n\n\n1574\n\n\nE00177871\n\n\n5169\n\n\n\n\n\n1575 rows × 2 columns"
  },
  {
    "objectID": "projects/20min_neighbourhoods/index.html#add-oa-polygons-back-in-and-map-choropleth",
    "href": "projects/20min_neighbourhoods/index.html#add-oa-polygons-back-in-and-map-choropleth",
    "title": "20-minute neighbourhoods: understanding housing density in Bradford",
    "section": "Add OA polygons back in and map choropleth",
    "text": "Add OA polygons back in and map choropleth\nThe results are easier to visualise using the OA polygons to remove any buffer overlap. Results show clear areas of higher density neighbourhoods, particuarly around large town in the district and the city centre.\n# Merge dataframes to add polygons back in\nfor_choropleth = pd.merge(Bradford_OA_polygons, agg_df, on='OA21CD', how='inner')\n# Visual check\nfor_choropleth\n\n\n\n\n\n\nOA21CD\n\n\nPolygon\n\n\nUPRN_Count\n\n\n\n\n\n\n0\n\n\nE00053353\n\n\nPOLYGON ((415817.093 440872.597, 415821.094 44…\n\n\n214\n\n\n\n\n1\n\n\nE00053354\n\n\nPOLYGON ((415078.000 439967.001, 415058.323 43…\n\n\n1148\n\n\n\n\n2\n\n\nE00053355\n\n\nPOLYGON ((416252.367 439816.041, 416253.270 43…\n\n\n1405\n\n\n\n\n3\n\n\nE00053356\n\n\nPOLYGON ((416668.000 439392.028, 416667.653 43…\n\n\n965\n\n\n\n\n4\n\n\nE00053357\n\n\nPOLYGON ((415143.909 439176.235, 415143.000 43…\n\n\n1441\n\n\n\n\n…\n\n\n…\n\n\n…\n\n\n…\n\n\n\n\n1570\n\n\nE00177806\n\n\nPOLYGON ((404057.041 446035.505, 404056.753 44…\n\n\n2069\n\n\n\n\n1571\n\n\nE00177807\n\n\nPOLYGON ((418884.032 438045.945, 418866.019 43…\n\n\n1790\n\n\n\n\n1572\n\n\nE00177808\n\n\nPOLYGON ((414782.332 437464.729, 414782.519 43…\n\n\n3114\n\n\n\n\n1573\n\n\nE00177809\n\n\nPOLYGON ((402252.845 444586.747, 402253.000 44…\n\n\n434\n\n\n\n\n1574\n\n\nE00177810\n\n\nPOLYGON ((410031.688 435427.501, 410026.053 43…\n\n\n489\n\n\n\n\n\n1575 rows × 3 columns\n\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Plot the choropleth map\nfor_choropleth.plot(column='UPRN_Count', cmap='inferno', legend=True, ax=ax, alpha=0.8)\n\n# Add basemap using contextily\ncx.add_basemap(ax, crs=for_choropleth.crs.to_string(), zoom=10)  # Set the coordinate reference system (CRS)\n\n# Set title\nplt.title('Housing density choropleth')\n\n# Turn off the axes\nax.axis('off')\n\n# Show the plot\nplt.show()\n\nplt.figure(figsize=(8, 6))\n\n# Create histogram\nplt.hist(for_choropleth['UPRN_Count'], bins=15, color='skyblue', edgecolor='black')  # Adjust the number of bins as needed\n\n# Add labels and title\nplt.xlabel('UPRN Count')\nplt.ylabel('Frequency')\nplt.title('Histogram of Housing Density')\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "projects/index.html#minute-neighbourhoods",
    "href": "projects/index.html#minute-neighbourhoods",
    "title": "Projects",
    "section": "20-minute neighbourhoods",
    "text": "20-minute neighbourhoods\n\n\n\n20-minute neighbourhoods: understanding housing density in Bradford\nDefining neighbourhoods using 800m buffers and identfying properties within these to understand housing density in the Bradford local authority district."
  },
  {
    "objectID": "projects/EV_charging/index.html",
    "href": "projects/EV_charging/index.html",
    "title": "Analysis of public EV chargepoint provision",
    "section": "",
    "text": "Go back to the projects page."
  },
  {
    "objectID": "projects/EV_charging/index.html#summary",
    "href": "projects/EV_charging/index.html#summary",
    "title": "Analysis of public EV chargepoint provision",
    "section": "Summary",
    "text": "Summary\nThis analysis uses public EV chargepoint and plug-in vehicle (PiV) registration data to understand, by local authority district (LAD), which areas have the best and worst EV infrastructure.\n\nWhat data is included?\nFirst, four features are calculated to allow for initial exploration of the data. Details of these are as follows:\nCount of PiVs\nSource: DVLA and DfT dataset\n\nA simple count of registered PiVs by LAD is calculated.\nThis includes all PiVs with Private keepership. This excludes PiVs where the keepership is Company to avoid skewing the analysis with large quantities of fleet vehicles registered to a single address.\nWhere data has been suppressed in the raw file, the [c] value has been replaced with NaN\n\nCount of EV chargepoints\nSource: Public EV chargepoint registry\n\nA simple count of public EV chargepoints by LAD is calculated.\nThere has been no cleaning of this data beyond converting the latitude and longitude into a point. This is a public dataset and further accuracy has not been verified.\n\nRatio of PiVs to EV chargepoints\nSource: Author’s calculations\n\nTaking the count of PiVs in each LAD and dividing this by the count of public EV chargepoints in each LAD.\nA higher ratio means there are more PiVs to each chargepoint and therefore public infrastructure may be lacking.\n\nAverage distance to nearest EV chargepoint\nSource: Geographies from ONS via Open Geography Portal\n\nUsing the population-weighted centroids (PWCs) for each output area (OA) within an LAD, the nearest public EV chargepoint is calculated. OA is the smallest census geography and contains between 40 and 250 households.\nThen this is aggregated to LAD level by taking the average distance of all OAs within the LAD to obtain the average distance to the nearest public EV chargepoint by LAD.\n\n\n\nWhat do these features show?\nThe following choropleths map these four features. The absolute number of PiVs varies across England and Wales, with LADs across Wales, Lincolnshire and Cumbria having particularly low numbers. By contrast, the highest number of public EV chargepoints by LAD is concentrated in Greater London, with hotspots dotted elsewhere across the country. If we instead look at this as the ratio of PiVs to chargepoints, we again see the patterns change. Hotspots around the southeast of England highlight that there is potentially infrastructure lacking in these areas compared to PiV numbers. Lastly, we can see the average distance to the nearest chargepoint is perhaps unsurprisingly highest in rural areas, particularly in the north of England and Wales.\n\nCode to create an interactive version of this map can be found below.\n\n\nWhat is the relationship between the features?\nThe correlation matrix heatmap below shows the relationship between each feature. There is some positive correlation between chargepoints and PiVs, which is good as this suggests that where there are more PiVs there tend to be more chargepoints. There is also some positive correlation between average distance to the nearest chargepoint and the ratio of PiVs to chargepoints. This means that if the distance is greater, there are also more PiVs to chargepoints perhaps suggesting these areas lack infrastructure.\n\nThe following scatter plots illustrate this further, adding a regression line. We can see that there are outliers across both, with a cluster of LADs on the lower end.\n\n\n\nSo what does this mean for public EV infrastructure?\nTaking the ratio of PiVs to public EV chargepoints and the average distance to the nearest chargepoint, a simple ranking is created combining the two. Areas with a high ratio of PiVs to chargepoints and a large distance to the nearest chargepoint could be lacking in public EV infrastructure.\nTop 10 The best performing LADs were all in London, suggesting infrastructure in the capital is well established.\n\n\n\n\n\n\n\nLAD22CD\n\n\nLAD22NM\n\n\ncombined_rank\n\n\n\n\n\n\n288\n\n\nE09000013\n\n\nHammersmith and Fulham\n\n\n1.0\n\n\n\n\n308\n\n\nE09000033\n\n\nWestminster\n\n\n2.0\n\n\n\n\n303\n\n\nE09000028\n\n\nSouthwark\n\n\n3.0\n\n\n\n\n276\n\n\nE09000001\n\n\nCity of London\n\n\n4.0\n\n\n\n\n295\n\n\nE09000020\n\n\nKensington and Chelsea\n\n\n4.0\n\n\n\n\n299\n\n\nE09000024\n\n\nMerton\n\n\n6.0\n\n\n\n\n307\n\n\nE09000032\n\n\nWandsworth\n\n\n6.0\n\n\n\n\n282\n\n\nE09000007\n\n\nCamden\n\n\n8.0\n\n\n\n\n287\n\n\nE09000012\n\n\nHackney\n\n\n9.0\n\n\n\n\n294\n\n\nE09000019\n\n\nIslington\n\n\n9.0\n\n\n\n\nBottom 10 The worst performing LADs are more dispersed. Most are more rural areas, or include only one or two larger towns.\n\n\n\n\n\n\n\nLAD22CD\n\n\nLAD22NM\n\n\ncombined_rank\n\n\n\n\n\n\n99\n\n\nE07000074\n\n\nMaldon\n\n\n330.0\n\n\n\n\n89\n\n\nE07000064\n\n\nRother\n\n\n329.0\n\n\n\n\n235\n\n\nE07000242\n\n\nEast Hertfordshire\n\n\n328.0\n\n\n\n\n16\n\n\nE06000017\n\n\nRutland\n\n\n327.0\n\n\n\n\n100\n\n\nE07000075\n\n\nRochford\n\n\n326.0\n\n\n\n\n85\n\n\nE07000047\n\n\nWest Devon\n\n\n325.0\n\n\n\n\n177\n\n\nE07000169\n\n\nSelby\n\n\n324.0\n\n\n\n\n160\n\n\nE07000139\n\n\nNorth Kesteven\n\n\n323.0\n\n\n\n\n82\n\n\nE07000044\n\n\nSouth Hams\n\n\n321.0\n\n\n\n\n199\n\n\nE07000198\n\n\nStaffordshire Moorlands\n\n\n321.0\n\n\n\n\nThis information could be used by both public and private organisations alike to understand where public EV infrastructure is lacking and therefore incentivise installation of new infrastructure.\n\n\nConsiderations and future work\nThis analysis has demonstrated that current public EV structure may be lacking in some areas based on the current number of PiVs. This does not include:\n\nA temporal view of how PiV ownership has changed over time - there may be areas experiencing higher growth, with could arguably justify increased investment over other areas.\nEV infrastructure on private property (e.g. at home) - areas with a higher number of terraced houses or flats may require more public infrastructure as it can often be more challenging to install at these types of properties. Areas with higher rates of rented accomodation over private ownership could also face challenges as it would be the responsibility of the landlord to install EV chargepoints. Again, these areas may require more public infrastructure and so overlaying this data could be an interesting investigation to see how it affects the ranking.\n\nThe public EV chargepoint registry has also not been quality checked. Further investigation into this dataset and wrangling/cleaning as appropriate may impact results."
  },
  {
    "objectID": "projects/EV_charging/index.html#coding",
    "href": "projects/EV_charging/index.html#coding",
    "title": "Analysis of public EV chargepoint provision",
    "section": "Coding",
    "text": "Coding"
  },
  {
    "objectID": "projects/EV_charging/index.html#import-libraries",
    "href": "projects/EV_charging/index.html#import-libraries",
    "title": "Analysis of public EV chargepoint provision",
    "section": "Import libraries",
    "text": "Import libraries\nimport pandas as pd\nimport geopandas as gpd\nfrom shapely.geometry import Point\nimport numpy as np\nimport seaborn as sns\nfrom scipy.stats import zscore\nimport matplotlib.pyplot as plt\nimport contextily as ctx\nimport folium"
  },
  {
    "objectID": "projects/EV_charging/index.html#data-wrangling",
    "href": "projects/EV_charging/index.html#data-wrangling",
    "title": "Analysis of public EV chargepoint provision",
    "section": "Data wrangling",
    "text": "Data wrangling\n\nEV Chargepoint data\n\nPublic EV chargepoint registry, available from: https://www.gov.uk/guidance/find-and-use-data-on-public-electric-vehicle-chargepoints\n\n# Import csv\nchargepoints_RAW = pd.read_csv('Data/national-charge-point-registry_230524.csv', low_memory=False)\n# Reduce to just required columns\nchargepoints_TRIM = chargepoints_RAW[['chargeDeviceID','reference','name','latitude','longitude']]\n# Check length of df\nlen(chargepoints_TRIM)\n40580\n# Visual check\nchargepoints_TRIM.head()\n\n\n\n\n\n\nchargeDeviceID\n\n\nreference\n\n\nname\n\n\nlatitude\n\n\nlongitude\n\n\n\n\n\n\n0\n\n\nb86a77a42bb68c81946ec50cfc95e89d\n\n\n11172306P\n\n\nNetwork Rail Westwood Centre 1\n\n\n52.386590\n\n\n-1.587384\n\n\n\n\n1\n\n\ndc1c347d471f68e41ad2a9a1145941d6\n\n\nAPT-0296-0015/13P\n\n\nBrindley Drive Car Park Birmingham - 70524\n\n\n52.480918\n\n\n-1.907710\n\n\n\n\n2\n\n\n7d545ad9367ccb8a80c94a953314ae71\n\n\nCM123\n\n\nRenault Liverpool\n\n\n53.383579\n\n\n-2.977230\n\n\n\n\n3\n\n\n68c7fca1e3bba5e49ec90847dcdd456b\n\n\nCM164\n\n\nNCP Portman Square\n\n\n51.516201\n\n\n-0.157996\n\n\n\n\n4\n\n\nac7a21c48f5833b33a5b606b2089e6a9\n\n\nCM167\n\n\nNCP Prince Street Car Park\n\n\n51.450340\n\n\n-2.596704\n\n\n\n\n# Geocode locations using lat and long, set crs to 4326 and then convert to 27700 (British National Grid), drop lat and long\nchargepoints_gdf = gpd.GeoDataFrame(chargepoints_TRIM,\n                                    geometry=gpd.points_from_xy(chargepoints_TRIM.longitude, chargepoints_TRIM.latitude)\n                                   ).set_crs(epsg=4326, inplace=True).to_crs(epsg=27700).drop(columns=['latitude','longitude'])\n# Visual check\nchargepoints_gdf.head()\n\n\n\n\n\n\nchargeDeviceID\n\n\nreference\n\n\nname\n\n\ngeometry\n\n\n\n\n\n\n0\n\n\nb86a77a42bb68c81946ec50cfc95e89d\n\n\n11172306P\n\n\nNetwork Rail Westwood Centre 1\n\n\nPOINT (428179.411 276586.797)\n\n\n\n\n1\n\n\ndc1c347d471f68e41ad2a9a1145941d6\n\n\nAPT-0296-0015/13P\n\n\nBrindley Drive Car Park Birmingham - 70524\n\n\nPOINT (406364.849 287003.294)\n\n\n\n\n2\n\n\n7d545ad9367ccb8a80c94a953314ae71\n\n\nCM123\n\n\nRenault Liverpool\n\n\nPOINT (335096.815 387859.900)\n\n\n\n\n3\n\n\n68c7fca1e3bba5e49ec90847dcdd456b\n\n\nCM164\n\n\nNCP Portman Square\n\n\nPOINT (527908.652 181305.630)\n\n\n\n\n4\n\n\nac7a21c48f5833b33a5b606b2089e6a9\n\n\nCM167\n\n\nNCP Prince Street Car Park\n\n\nPOINT (358631.700 172541.813)\n\n\n\n\n\n\nEV Cars data\n\ndf_VEH0145: Licensed plug-in vehicles (PiVs) at the end of the quarter by fuel type and lower super output area (LSOA): United Kingdom, available from: https://www.gov.uk/government/statistical-data-sets/vehicle-licensing-statistics-data-files\n\n# Import csv\nPiVs_RAW = pd.read_csv('Data/df_VEH0145.csv', low_memory=False)\n# Reduce to just required columns\nPiVs_TRIM = PiVs_RAW[['LSOA11CD','LSOA11NM','Fuel','Keepership','2023 Q4']]\n# Visual check\nPiVs_TRIM.head()\n\n\n\n\n\n\nLSOA11CD\n\n\nLSOA11NM\n\n\nFuel\n\n\nKeepership\n\n\n2023 Q4\n\n\n\n\n\n\n0\n\n\n95AA01S1\n\n\nAldergrove 1\n\n\nBattery electric\n\n\nCompany\n\n\n[c]\n\n\n\n\n1\n\n\n95AA01S2\n\n\nAldergrove 2\n\n\nBattery electric\n\n\nCompany\n\n\n9\n\n\n\n\n2\n\n\n95AA01S3\n\n\nAldergrove 3\n\n\nBattery electric\n\n\nCompany\n\n\n[c]\n\n\n\n\n3\n\n\n95AA02W1\n\n\nBalloo\n\n\nBattery electric\n\n\nCompany\n\n\n5\n\n\n\n\n4\n\n\n95AA03W1\n\n\nBallycraigy\n\n\nBattery electric\n\n\nCompany\n\n\n[c]\n\n\n\n\n# Filter to all Fuel and private Keepership types, then drop those columns\nPiVs_FILTERED = PiVs_TRIM[(PiVs_TRIM['Fuel'] == 'Total') & \n                          (PiVs_TRIM['Keepership'] == 'Private')].drop(columns=['Fuel', 'Keepership'])\n# Replace the suppressed [c] data with NaN\nPiVs_FILTERED['2023 Q4'] = PiVs_FILTERED['2023 Q4'].replace('[c]', np.nan)\n\n# Convert the '2023 Q4' column to numeric data type\nPiVs_FILTERED['2023 Q4'] = pd.to_numeric(PiVs_FILTERED['2023 Q4'])\n# Visual check\nPiVs_FILTERED.head()\n\n\n\n\n\n\nLSOA11CD\n\n\nLSOA11NM\n\n\n2023 Q4\n\n\n\n\n\n\n189862\n\n\n95AA01S1\n\n\nAldergrove 1\n\n\nNaN\n\n\n\n\n189863\n\n\n95AA01S2\n\n\nAldergrove 2\n\n\n15.0\n\n\n\n\n189864\n\n\n95AA01S3\n\n\nAldergrove 3\n\n\n19.0\n\n\n\n\n189865\n\n\n95AA02W1\n\n\nBalloo\n\n\n10.0\n\n\n\n\n189866\n\n\n95AA03W1\n\n\nBallycraigy\n\n\nNaN\n\n\n\n\n\nLSOA lookup\nThe PiV data uses the LSOA codes from 2011 and so this will need to be changed to the LSOA 2021 codes.\n\nLSOA best fit lookup 2011 to 2021, available from: https://geoportal.statistics.gov.uk/datasets/b14d449ba10a48508bd05cd4a9775e2b_0/explore\n\n# Import csv\nLSOA_lookup = pd.read_csv(\n    'Data/LSOA_(2011)_to_LSOA_(2021)_to_Local_Authority_District_(2022)_Best_Fit_Lookup_for_EW_(V2).csv',\n    low_memory=False)\n# Reduce to just required columns\nLSOA_lookup = LSOA_lookup[['LSOA11CD','LSOA21CD','LAD22CD','LAD22NM']].copy()\n# Match 2021 to 2011 codes using lookup\nPiVs_FILTERED = pd.merge(PiVs_FILTERED, LSOA_lookup, on='LSOA11CD')\n# Visual check\nPiVs_FILTERED.head()\n\n\n\n\n\n\nLSOA11CD\n\n\nLSOA11NM\n\n\n2023 Q4\n\n\nLSOA21CD\n\n\nLAD22CD\n\n\nLAD22NM\n\n\n\n\n\n\n0\n\n\nE01000001\n\n\nCity of London 001A\n\n\n28.0\n\n\nE01000001\n\n\nE09000001\n\n\nCity of London\n\n\n\n\n1\n\n\nE01000002\n\n\nCity of London 001B\n\n\n30.0\n\n\nE01000002\n\n\nE09000001\n\n\nCity of London\n\n\n\n\n2\n\n\nE01000003\n\n\nCity of London 001C\n\n\n15.0\n\n\nE01000003\n\n\nE09000001\n\n\nCity of London\n\n\n\n\n3\n\n\nE01000005\n\n\nCity of London 001E\n\n\nNaN\n\n\nE01000005\n\n\nE09000001\n\n\nCity of London\n\n\n\n\n4\n\n\nE01000006\n\n\nBarking and Dagenham 016A\n\n\n18.0\n\n\nE01000006\n\n\nE09000002\n\n\nBarking and Dagenham\n\n\n\n\n\n\n\nLADs\n\nLADs 2021 polygons, available from: https://geoportal.statistics.gov.uk/datasets/305779d69bf44feea05eeaa78ca26b5f_0/explore\n\n# Import shp file\nLADs = gpd.read_file('Data/Local_Authority_Districts_December_2022_UK_BFC_V2_-177113771882051469/LAD_DEC_2022_UK_BFC_V2.shp')\n# Reduce to just required columns\nLADs = LADs[['LAD22CD','LAD22NM','geometry']].copy()\n# Visual check\nLADs.head()\n\n\n\n\n\n\nLAD22CD\n\n\nLAD22NM\n\n\ngeometry\n\n\n\n\n\n\n0\n\n\nE06000001\n\n\nHartlepool\n\n\nMULTIPOLYGON (((450154.599 525938.201, 450140….\n\n\n\n\n1\n\n\nE06000002\n\n\nMiddlesbrough\n\n\nMULTIPOLYGON (((446854.700 517192.700, 446854….\n\n\n\n\n2\n\n\nE06000003\n\n\nRedcar and Cleveland\n\n\nMULTIPOLYGON (((451747.397 520561.100, 451792….\n\n\n\n\n3\n\n\nE06000004\n\n\nStockton-on-Tees\n\n\nMULTIPOLYGON (((447177.704 517811.797, 447176….\n\n\n\n\n4\n\n\nE06000005\n\n\nDarlington\n\n\nPOLYGON ((423496.602 524724.299, 423497.204 52…\n\n\n\n\nlen(LADs)\n374\n\n\nOAs\nThis analysis will use the population-weighted centroids (PWCs) to find the nearest EV chargepoints. This will then be aggregated to LAD level, so the OA to LAD lookup is required.\n\nOA 2021 PWCs, available from: https://geoportal.statistics.gov.uk/datasets/b9b2b2440af240ce9d30a1d39a7507c2_0/explore\nOA to LAD lookup, available from: https://geoportal.statistics.gov.uk/datasets/b9ca90c10aaa4b8d9791e9859a38ca67_0/explore\n\n\nOA PWCs\n# Import shp file\nOA_PWC = gpd.read_file('Data/Output_Areas_2021_PWC_V3_-1981902074309169314/PopCentroids_EW_2021_V3.shp')\n# Reduce to just required columns\nOA_PWC = OA_PWC[['OA21CD','geometry']].copy()\n\n\nOA to LAD lookup\n# Import csv\nOA_lookup = pd.read_csv(\n    'Data/Output_Area_to_Lower_layer_Super_Output_Area_to_Middle_layer_Super_Output_Area_to_Local_Authority_District_(December_2021)_Lookup_in_England_and_Wales_v3.csv',\n    low_memory=False)\n# Keep only required columns\nOA_lookup = OA_lookup[['OA21CD','LSOA21CD','LAD22CD']].copy()\n# Visual check\nOA_lookup.head()\n\n\n\n\n\n\nOA21CD\n\n\nLSOA21CD\n\n\nLAD22CD\n\n\n\n\n\n\n0\n\n\nE00060358\n\n\nE01011968\n\n\nE06000001\n\n\n\n\n1\n\n\nE00060359\n\n\nE01011968\n\n\nE06000001\n\n\n\n\n2\n\n\nE00060360\n\n\nE01011968\n\n\nE06000001\n\n\n\n\n3\n\n\nE00060361\n\n\nE01011968\n\n\nE06000001\n\n\n\n\n4\n\n\nE00060362\n\n\nE01011970\n\n\nE06000001"
  },
  {
    "objectID": "projects/EV_charging/index.html#feature-engineering",
    "href": "projects/EV_charging/index.html#feature-engineering",
    "title": "Analysis of public EV chargepoint provision",
    "section": "Feature engineering",
    "text": "Feature engineering\n\nAggregate EV car ownership data to LAD\n# Aggregate to LAD and calculate total number of PiVs\nPiVs_LAD = PiVs_FILTERED.groupby('LAD22CD')['2023 Q4'].agg('sum').reset_index()\n\n# Rename column to PiVs\nPiVs_LAD.rename(columns={'2023 Q4': 'PiVs'}, inplace=True)\n# Visual check\nPiVs_LAD.head()\n\n\n\n\n\n\nLAD22CD\n\n\nPiVs\n\n\n\n\n\n\n0\n\n\nE06000001\n\n\n410.0\n\n\n\n\n1\n\n\nE06000002\n\n\n391.0\n\n\n\n\n2\n\n\nE06000003\n\n\n580.0\n\n\n\n\n3\n\n\nE06000004\n\n\n1308.0\n\n\n\n\n4\n\n\nE06000005\n\n\n719.0\n\n\n\n\nlen(PiVs_LAD)\n331\n\n\nCalculate distance to nearest chargepoint\n\nUsing the OA PWCs, calculate the nearest EV chargepoint.\nAggregate this to LAD level to get the average distance to the nearest chargepoint by LAD.\n\n# Find the nearest chargepoint to each OA PWC and calculate distance in metres\nOA_nearest_chargepoint = OA_PWC.sjoin_nearest(chargepoints_gdf, distance_col='distance', how='left')\n# Merge on OA_lookup_Leeds to get the LAD22CDs\nOA_nearest_chargepoint = pd.merge(OA_nearest_chargepoint, OA_lookup, on='OA21CD', how='inner')\n# Keep only required columns\nOA_nearest_chargepoint = OA_nearest_chargepoint[['OA21CD','geometry','distance','LAD22CD']].copy()\n# Aggregate to LAD and calculate average distance to nearest chargepoint\navg_dist_nearest_chargepoint_LAD = OA_nearest_chargepoint.groupby('LAD22CD')['distance'].agg('mean').reset_index()\n\n# Rename column to avg_distance\navg_dist_nearest_chargepoint_LAD.rename(columns={'distance': 'avg_distance'}, inplace=True)\n# Visual check\navg_dist_nearest_chargepoint_LAD.head()\n\n\n\n\n\n\nLAD22CD\n\n\navg_distance\n\n\n\n\n\n\n0\n\n\nE06000001\n\n\n1649.498055\n\n\n\n\n1\n\n\nE06000002\n\n\n1088.305461\n\n\n\n\n2\n\n\nE06000003\n\n\n1454.585351\n\n\n\n\n3\n\n\nE06000004\n\n\n911.259807\n\n\n\n\n4\n\n\nE06000005\n\n\n1188.923394\n\n\n\n\nlen(avg_dist_nearest_chargepoint_LAD)\n331\n\n\nCalculate number of EV chargepoints in each LAD\n\nAggregate the EV chargepoint data to LAD level to get total number of chargepoints in each LAD.\n\n# Spatially match\nchargepoints_LAD = gpd.sjoin(LADs, chargepoints_gdf, predicate='intersects')\n# Aggregate to LAD and calculate total number of chargepoints\nchargepoints_LAD = chargepoints_LAD.groupby('LAD22CD')['index_right'].agg('count').reset_index()\n\n# Rename column to total_chargepoints\nchargepoints_LAD.rename(columns={'index_right': 'total_chargepoints'}, inplace=True)\n# Visual check\nchargepoints_LAD.head()\n\n\n\n\n\n\nLAD22CD\n\n\ntotal_chargepoints\n\n\n\n\n\n\n0\n\n\nE06000001\n\n\n42\n\n\n\n\n1\n\n\nE06000002\n\n\n51\n\n\n\n\n2\n\n\nE06000003\n\n\n46\n\n\n\n\n3\n\n\nE06000004\n\n\n167\n\n\n\n\n4\n\n\nE06000005\n\n\n76\n\n\n\n\nlen(chargepoints_LAD)\n373\n\n\nCalculate ratio of EV cars to chargepoints in each LAD\n# Merge PiVs and chargepoint count dataframes\nratio_PiVs_to_chargepoints = pd.merge(PiVs_LAD, chargepoints_LAD, on='LAD22CD', how='left')\n\n# Replace NaN values with 0 where there are no chargepoints in an MSOA\nratio_PiVs_to_chargepoints.fillna({'total_chargepoints': 0}, inplace=True)\n# Calculate ratio\nratio_PiVs_to_chargepoints['ratio_PiVs_to_chargepoints'] = (\n    ratio_PiVs_to_chargepoints['PiVs'] / ratio_PiVs_to_chargepoints['total_chargepoints'])\n\n# Replace 'inf' with NaN\nratio_PiVs_to_chargepoints['ratio_PiVs_to_chargepoints'] = ratio_PiVs_to_chargepoints[\n    'ratio_PiVs_to_chargepoints'].replace([np.inf, -np.inf], np.nan)\n\n\nAdd average distance and LAD polygon to final dataframe\n# Add nearest chargepoint\nfinal_df = pd.merge(ratio_PiVs_to_chargepoints,avg_dist_nearest_chargepoint_LAD, on='LAD22CD')\n\n# Add LAD polygons\nfinal_df = pd.merge(LADs, final_df, on='LAD22CD')\n# Visual check\nfinal_df.head()\n\n\n\n\n\n\nLAD22CD\n\n\nLAD22NM\n\n\ngeometry\n\n\nPiVs\n\n\ntotal_chargepoints\n\n\nratio_PiVs_to_chargepoints\n\n\navg_distance\n\n\n\n\n\n\n0\n\n\nE06000001\n\n\nHartlepool\n\n\nMULTIPOLYGON (((450154.599 525938.201, 450140….\n\n\n410.0\n\n\n42.0\n\n\n9.761905\n\n\n1649.498055\n\n\n\n\n1\n\n\nE06000002\n\n\nMiddlesbrough\n\n\nMULTIPOLYGON (((446854.700 517192.700, 446854….\n\n\n391.0\n\n\n51.0\n\n\n7.666667\n\n\n1088.305461\n\n\n\n\n2\n\n\nE06000003\n\n\nRedcar and Cleveland\n\n\nMULTIPOLYGON (((451747.397 520561.100, 451792….\n\n\n580.0\n\n\n46.0\n\n\n12.608696\n\n\n1454.585351\n\n\n\n\n3\n\n\nE06000004\n\n\nStockton-on-Tees\n\n\nMULTIPOLYGON (((447177.704 517811.797, 447176….\n\n\n1308.0\n\n\n167.0\n\n\n7.832335\n\n\n911.259807\n\n\n\n\n4\n\n\nE06000005\n\n\nDarlington\n\n\nPOLYGON ((423496.602 524724.299, 423497.204 52…\n\n\n719.0\n\n\n76.0\n\n\n9.460526\n\n\n1188.923394\n\n\n\n\n\n\nHandle outliers\nThere are some outliers on the top end, so anything outside 2sd will be amended.\n# Loop through each variable and calculate mean, std, and threshold\nfor variable in ['PiVs', 'total_chargepoints', 'ratio_PiVs_to_chargepoints', 'avg_distance']:\n    mean_var = final_df[variable].mean()\n    std_var = final_df[variable].std()\n    threshold_var = mean_var + 2 * std_var\n    \n    # Create new column based on outlier condition\n    final_df[f'amended_{variable}'] = final_df[variable].apply(lambda x: threshold_var if x &gt; threshold_var else x)\n# Visual check\nfinal_df.head()\n\n\n\n\n\n\nLAD22CD\n\n\nLAD22NM\n\n\ngeometry\n\n\nPiVs\n\n\ntotal_chargepoints\n\n\nratio_PiVs_to_chargepoints\n\n\navg_distance\n\n\namended_PiVs\n\n\namended_total_chargepoints\n\n\namended_ratio_PiVs_to_chargepoints\n\n\namended_avg_distance\n\n\n\n\n\n\n0\n\n\nE06000001\n\n\nHartlepool\n\n\nMULTIPOLYGON (((450154.599 525938.201, 450140….\n\n\n410.0\n\n\n42.0\n\n\n9.761905\n\n\n1649.498055\n\n\n410.0\n\n\n42.0\n\n\n9.761905\n\n\n1649.498055\n\n\n\n\n1\n\n\nE06000002\n\n\nMiddlesbrough\n\n\nMULTIPOLYGON (((446854.700 517192.700, 446854….\n\n\n391.0\n\n\n51.0\n\n\n7.666667\n\n\n1088.305461\n\n\n391.0\n\n\n51.0\n\n\n7.666667\n\n\n1088.305461\n\n\n\n\n2\n\n\nE06000003\n\n\nRedcar and Cleveland\n\n\nMULTIPOLYGON (((451747.397 520561.100, 451792….\n\n\n580.0\n\n\n46.0\n\n\n12.608696\n\n\n1454.585351\n\n\n580.0\n\n\n46.0\n\n\n12.608696\n\n\n1454.585351\n\n\n\n\n3\n\n\nE06000004\n\n\nStockton-on-Tees\n\n\nMULTIPOLYGON (((447177.704 517811.797, 447176….\n\n\n1308.0\n\n\n167.0\n\n\n7.832335\n\n\n911.259807\n\n\n1308.0\n\n\n167.0\n\n\n7.832335\n\n\n911.259807\n\n\n\n\n4\n\n\nE06000005\n\n\nDarlington\n\n\nPOLYGON ((423496.602 524724.299, 423497.204 52…\n\n\n719.0\n\n\n76.0\n\n\n9.460526\n\n\n1188.923394\n\n\n719.0\n\n\n76.0\n\n\n9.460526\n\n\n1188.923394"
  },
  {
    "objectID": "projects/EV_charging/index.html#visualising-data",
    "href": "projects/EV_charging/index.html#visualising-data",
    "title": "Analysis of public EV chargepoint provision",
    "section": "Visualising data",
    "text": "Visualising data\nThe following code builds an interactive map of the features in final_df. This is saved down into an Outputs/ folder as an HTML file.\n# Create the individual layers\nm = final_df.explore(\n    column=\"amended_PiVs\",\n    scheme=\"naturalbreaks\",\n    cmap='YlOrRd',\n    legend=False,\n    k=10,\n    tooltip=[\"LAD22CD\", \"LAD22NM\", \"amended_PiVs\"],\n    style_kwds=dict(color='black', weight=0.5, fillOpacity=0.8),\n    highlight_kwds=dict(fillOpacity=1),\n    name=\"Plug-in Vehicles\",\n    show=True)\n\nfinal_df.explore(\n    m=m,\n    column=\"amended_total_chargepoints\",\n    scheme=\"naturalbreaks\",\n    cmap='YlOrRd',\n    legend=False,\n    k=10,\n    tooltip=[\"LAD22CD\", \"LAD22NM\", \"amended_total_chargepoints\"],\n    style_kwds=dict(color='black', weight=0.5, fillOpacity=0.8),\n    highlight_kwds=dict(fillOpacity=1),\n    name=\"Total EV Chargepoints\",\n    show=False)\n\nfinal_df.explore(\n    m=m,\n    column=\"amended_ratio_PiVs_to_chargepoints\",\n    scheme=\"naturalbreaks\",\n    cmap='YlOrRd',\n    legend=False,\n    k=10,\n    tooltip=[\"LAD22CD\", \"LAD22NM\", \"amended_ratio_PiVs_to_chargepoints\"],\n    style_kwds=dict(color='black', weight=0.5, fillOpacity=0.8),\n    highlight_kwds=dict(fillOpacity=1),\n    name=\"Ratio of Plug-in Vehicles to EV Chargepoints\",\n    show=False)\n\nfinal_df.explore(\n    m=m,\n    column=\"amended_avg_distance\",\n    scheme=\"naturalbreaks\",\n    cmap='YlOrRd',\n    legend=False,\n    k=10,\n    tooltip=[\"LAD22CD\", \"LAD22NM\", \"amended_avg_distance\"],\n    style_kwds=dict(color='black', weight=0.5, fillOpacity=0.8),\n    highlight_kwds=dict(fillOpacity=1),\n    name=\"Average distance to nearest EV Chargepoint by OA\",\n    show=False)\n\n# Add the map base\nfolium.TileLayer(\"CartoDB positron\", show=True).add_to(m)\n\n# Add layer control to map\nfolium.LayerControl().add_to(m)\n\n# Save the map to an HTML file\nm.save(\"Outputs/Interactive_map.html\")\nThe following code builds four choropleth maps of the features in final_df. This is saved down into an Outputs/ folder as a .png file.\n# Create 2x2 subplots\nfig, axs = plt.subplots(2, 2, figsize=(12, 12))\n\n# Define aliases for column names\ncolumn_aliases = {\n    'amended_PiVs': 'Plug-in Vehicles (PiVs)',\n    'amended_total_chargepoints': 'Total EV Chargepoints (EVCs)',\n    'amended_ratio_PiVs_to_chargepoints': 'Ratio of PiVs to EVCs',\n    'amended_avg_distance': 'Average distance to nearest EVC by OA (metres)'\n}\n\n# Loop through each variable and corresponding subplot\nvariables = list(column_aliases.keys())\nfor variable, ax in zip(variables, axs.flatten()):\n    final_df.plot(column=variable, cmap='YlOrRd', ax=ax, legend=True)\n    ax.set_title(f'{column_aliases[variable]}')  # Set the title using the alias\n    ax.set_axis_off()  # Turn off axis\n    \nplt.subplots_adjust(wspace=0.05, hspace=0.05)  # Adjust space between subplots\nplt.tight_layout()  # Adjust layout to prevent overlap\n\n# Export to Outputs/ folder\nplt.savefig('Outputs/Feature_choropleths.png', dpi=300)\n\n# Close figure\nplt.close(fig)\nThe following code creates two scatterplots with regression lines for selected features from the final_df. This is saved down into an Outputs/ folder as a .png file.\n# Create a subplot grid with 1 row and 2 columns\nfig, axs = plt.subplots(1, 2, figsize=(15, 6))\n\n# Plot the first scatter plot\nsns.scatterplot(x='amended_PiVs', y='amended_total_chargepoints', data=final_df, ax=axs[0])\nsns.regplot(x='amended_PiVs', y='amended_total_chargepoints', data=final_df, scatter=False, ax=axs[0])\naxs[0].set_xlabel(column_aliases['amended_PiVs'])  # Set x-axis label using alias\naxs[0].set_ylabel(column_aliases['amended_total_chargepoints'])  # Set y-axis label using alias\naxs[0].set_title('Plug-in Vehicles vs. Total EV Chargepoints')  # Set the title\n\n# Plot the second scatter plot\nsns.scatterplot(x='amended_ratio_PiVs_to_chargepoints', y='amended_avg_distance', data=final_df, ax=axs[1])\nsns.regplot(x='amended_ratio_PiVs_to_chargepoints', y='amended_avg_distance', data=final_df, scatter=False, ax=axs[1])\naxs[1].set_xlabel(column_aliases['amended_ratio_PiVs_to_chargepoints'])  # Set x-axis label using alias\naxs[1].set_ylabel(column_aliases['amended_avg_distance'])  # Set y-axis label using alias\naxs[1].set_title('Ratio vs. Distance')  # Set the title\n\n# Adjust layout\nplt.tight_layout()\n\n# Export to Outputs/ folder\nplt.savefig('Outputs/Scatter_Reg_Plots.png', dpi=300)\n\n# Close figure\nplt.close(fig)\nThe following code creates a correlation matrix heatmap of the features in final_df. This is saved down into an Outputs/ folder as a .png file.\n# Calculate the correlation matrix\ncorrelation_matrix = final_df[[\n    'amended_PiVs','amended_total_chargepoints',\n    'amended_ratio_PiVs_to_chargepoints','amended_avg_distance']].corr()\n\n# Generate a mask for the diagonal cells\nmask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n\n# Generate a heatmap\nplt.figure(figsize=(8, 7))\nsns.heatmap(correlation_matrix, cmap='RdYlGn', annot=True, \n            fmt=\".2f\", mask=mask, vmin=-1, vmax=1, cbar_kws={\"shrink\": 0.75}, linewidth=.5)\n\n# Rotate axis labels\nplt.xticks(rotation=45)\nplt.yticks(rotation=45)\n\n# Set axis labels using aliases and wrap text\nplt.xticks(ticks=range(len(correlation_matrix.columns)), \n           labels=['Plug-in Vehicles', \n                   'Total EV Chargepoints', \n                   'Ratio of PiVs to EVCs', \n                   'Avg dist to nearest EVC'])\n\nplt.yticks(ticks=np.arange(len(correlation_matrix.columns))+0.5, \n           labels=['Plug-in Vehicles', \n                   'Total EV Chargepoints', \n                   'Ratio of PiVs to EVCs', \n                   'Avg dist to nearest EVC'])\n\nplt.title('Correlation Matrix Heatmap', fontweight='bold')\n\nplt.tight_layout()\n\n# Export to Outputs/ folder\nplt.savefig('Outputs/CorrelationMatrix.png', dpi=300)\n\n# Close figure\nplt.close()"
  },
  {
    "objectID": "projects/EV_charging/index.html#creating-a-ranking",
    "href": "projects/EV_charging/index.html#creating-a-ranking",
    "title": "Analysis of public EV chargepoint provision",
    "section": "Creating a ranking",
    "text": "Creating a ranking\nThe following code creates a simple ranking of LADs based on:\n\nAverage distance to the nearest EV chargepoint\nRatio of Plug-in vehicles to EV chargepoints\n\nThe idea is that if the average distance is high, and the ratio is high, then these areas may be lacking public EV infrastructure.\n# Create a new dataframe containing just the amended features for the ranking\nranking = final_df.drop(final_df.columns[3:9], axis=1)\n# Rank the values in each column\nranking['rank_ratio'] = ranking['amended_ratio_PiVs_to_chargepoints'].rank(ascending=True, method='min')\nranking['rank_distance'] = ranking['amended_avg_distance'].rank(ascending=True, method='min')\n# Compute the combined ranking\nranking['combined_rank'] = (ranking['rank_ratio'] + ranking['rank_distance']) / 2\nranking['combined_rank'] = ranking['combined_rank'].rank(ascending=True, method='min')\nThe following code creates a map of the top 10 combined_rank LADs in ranking. This is saved down into an Outputs/ folder as a .png file.\n# Get top 10 areas\nranking[['LAD22CD','LAD22NM','combined_rank']].sort_values(by='combined_rank', ascending=True).head(10)\n\n\n\n\n\n\nLAD22CD\n\n\nLAD22NM\n\n\ncombined_rank\n\n\n\n\n\n\n288\n\n\nE09000013\n\n\nHammersmith and Fulham\n\n\n1.0\n\n\n\n\n308\n\n\nE09000033\n\n\nWestminster\n\n\n2.0\n\n\n\n\n303\n\n\nE09000028\n\n\nSouthwark\n\n\n3.0\n\n\n\n\n276\n\n\nE09000001\n\n\nCity of London\n\n\n4.0\n\n\n\n\n295\n\n\nE09000020\n\n\nKensington and Chelsea\n\n\n4.0\n\n\n\n\n299\n\n\nE09000024\n\n\nMerton\n\n\n6.0\n\n\n\n\n307\n\n\nE09000032\n\n\nWandsworth\n\n\n6.0\n\n\n\n\n282\n\n\nE09000007\n\n\nCamden\n\n\n8.0\n\n\n\n\n287\n\n\nE09000012\n\n\nHackney\n\n\n9.0\n\n\n\n\n294\n\n\nE09000019\n\n\nIslington\n\n\n9.0\n\n\n\n\n# Sort and select the top 10 areas\ntop_10_areas = ranking.sort_values(by='combined_rank', ascending=True).head(10)\n\n# Plot only the top 10 areas\nfig, ax = plt.subplots(1, 1, figsize=(8, 10))\ntop_10_areas.plot(ax=ax, color='#88C88E', edgecolor='black', linewidth=1, legend=True, alpha=0.5)\n\n# Annotate the top 10 areas with their rank\nfor idx, row in top_10_areas.iterrows():\n    plt.annotate(text=int(row['combined_rank']), xy=(row.geometry.centroid.x, row.geometry.centroid.y),\n                 horizontalalignment='center', fontsize=12, weight='bold', color='black')\n\n# Plot basemap\nctx.add_basemap(ax, crs=top_10_areas.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n\n# Set title and remove axis\nax.set_title('Top 10 Areas by Combined Rank', fontsize=12, fontweight='bold')\nax.set_axis_off()\n\n# Adjust layout\nplt.tight_layout()\n\n# Export to Outputs/ folder\nplt.savefig('Outputs/Map_of_Top_10.png', dpi=300)\n\n# Close figure\nplt.close(fig)\nThe following code creates a map of the bottom 10 combined_rank LADs in ranking. This is saved down into an Outputs/ folder as a .png file.\n# Show bottom 10 areas\nranking[['LAD22CD','LAD22NM','combined_rank']].sort_values(by='combined_rank', ascending=False).head(10)\n\n\n\n\n\n\nLAD22CD\n\n\nLAD22NM\n\n\ncombined_rank\n\n\n\n\n\n\n99\n\n\nE07000074\n\n\nMaldon\n\n\n330.0\n\n\n\n\n89\n\n\nE07000064\n\n\nRother\n\n\n329.0\n\n\n\n\n235\n\n\nE07000242\n\n\nEast Hertfordshire\n\n\n328.0\n\n\n\n\n16\n\n\nE06000017\n\n\nRutland\n\n\n327.0\n\n\n\n\n100\n\n\nE07000075\n\n\nRochford\n\n\n326.0\n\n\n\n\n85\n\n\nE07000047\n\n\nWest Devon\n\n\n325.0\n\n\n\n\n177\n\n\nE07000169\n\n\nSelby\n\n\n324.0\n\n\n\n\n160\n\n\nE07000139\n\n\nNorth Kesteven\n\n\n323.0\n\n\n\n\n82\n\n\nE07000044\n\n\nSouth Hams\n\n\n321.0\n\n\n\n\n199\n\n\nE07000198\n\n\nStaffordshire Moorlands\n\n\n321.0\n\n\n\n\n# Sort and select the bottom 10 areas\nbottom_10_areas = ranking.sort_values(by='combined_rank', ascending=False).head(10)\n\n# Plot only the top 10 areas\nfig, ax = plt.subplots(1, 1, figsize=(10, 10))\nbottom_10_areas.plot(ax=ax, color='#DE6464', edgecolor='black', linewidth=1, legend=True, alpha=0.5)\n\n# Annotate the top 10 areas with their rank\nfor idx, row in bottom_10_areas.iterrows():\n    plt.annotate(text=int(row['combined_rank']), xy=(row.geometry.centroid.x, row.geometry.centroid.y),\n                 horizontalalignment='center', fontsize=12, weight='bold', color='black')\n\n# Plot basemap\nctx.add_basemap(ax, crs=bottom_10_areas.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n\n# Set title and remove axis\nax.set_title('Bottom 10 Areas by Combined Rank', fontsize=12, fontweight='bold')\nax.set_axis_off()\n\n# Adjust layout\nplt.tight_layout()\n\n# Export to Outputs/ folder\nplt.savefig('Outputs/Map_of_Bottom_10.png', dpi=300)\n\n# Close figure\nplt.close(fig)"
  },
  {
    "objectID": "projects/index.html#ev-charging",
    "href": "projects/index.html#ev-charging",
    "title": "Projects",
    "section": "EV charging",
    "text": "EV charging\n\n\n\nAnalysis of public EV chargepoint provision\nUsing public EV chargepoint and plug-in vehicle registration data to understand, by local authority, which areas have the best and worst public EV infrastructure."
  }
]